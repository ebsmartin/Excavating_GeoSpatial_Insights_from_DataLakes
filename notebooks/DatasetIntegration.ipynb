{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset Integration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n",
      "/usr/bin/python3.9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/local/python-env/py39/lib/python3.9/site-packages\")\n",
    "\n",
    "import pyspark\n",
    "print(pyspark.__version__)\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialze a SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring the pyspark library is being accessed from my local usr directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Sedona version: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "sedona_version = pkg_resources.get_distribution(\"apache-sedona\").version\n",
    "print(f\"Apache Sedona version: {sedona_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/latest\n",
      "/usr/bin/python3.9\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['SPARK_HOME'])\n",
    "print(os.environ['PYSPARK_PYTHON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SedonaKepler import, verify if keplergl is installed\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import col, lit,  split, expr, concat, when, explode\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType, DateType\n",
    "from pyspark.sql.functions import year \n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import sum as pyspark_sum\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql import SparkSession\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "from sedona.spark import *\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to make the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://artifacts.unidata.ucar.edu/repository/unidata-all added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /s/chopin/a/grad/flarrieu/.ivy2/cache\n",
      "The jars for the packages stored in: /s/chopin/a/grad/flarrieu/.ivy2/jars\n",
      "org.apache.sedona#sedona-spark-3.5_2.12 added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ce28daa3-3029-4a04-ac2d-9eb62b97621d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.sedona#sedona-spark-3.5_2.12;1.5.1 in central\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark/3.5.0-with-hadoop3.3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.sedona#sedona-common;1.5.1 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in central\n",
      "\tfound org.locationtech.jts#jts-core;1.19.0 in central\n",
      "\tfound org.wololo#jts2geojson;0.16.1 in central\n",
      "\tfound org.locationtech.spatial4j#spatial4j;0.8 in central\n",
      "\tfound com.google.geometry#s2-geometry;2.0.0 in central\n",
      "\tfound com.google.guava#guava;25.1-jre in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in user-list\n",
      "\tfound org.checkerframework#checker-qual;2.0.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.1.3 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.14 in central\n",
      "\tfound com.uber#h3;4.1.1 in central\n",
      "\tfound net.sf.geographiclib#GeographicLib-Java;1.52 in central\n",
      "\tfound com.github.ben-manes.caffeine#caffeine;2.9.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.10.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.5.1 in central\n",
      "\tfound org.apache.sedona#sedona-spark-common-3.5_2.12;1.5.1 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in user-list\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 in central\n",
      "\tfound org.beryx#awt-color-factory;1.0.0 in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.5.1-28.2 in central\n",
      ":: resolution report :: resolve 931ms :: artifacts dl 44ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.ben-manes.caffeine#caffeine;2.9.2 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from user-list in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.5.1 from central in [default]\n",
      "\tcom.google.geometry#s2-geometry;2.0.0 from central in [default]\n",
      "\tcom.google.guava#guava;25.1-jre from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.uber#h3;4.1.1 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from user-list in [default]\n",
      "\tnet.sf.geographiclib#GeographicLib-Java;1.52 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-common;1.5.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-3.5_2.12;1.5.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-common-3.5_2.12;1.5.1 from central in [default]\n",
      "\torg.beryx#awt-color-factory;1.0.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.10.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.14 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.5.1-28.2 from central in [default]\n",
      "\torg.locationtech.jts#jts-core;1.19.0 from central in [default]\n",
      "\torg.locationtech.spatial4j#spatial4j;0.8 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.5.0 from central in [default]\n",
      "\torg.wololo#jts2geojson;0.16.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.checkerframework#checker-qual;2.0.0 by [org.checkerframework#checker-qual;3.10.0] in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.1.3 by [com.google.errorprone#error_prone_annotations;2.5.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   23  |   1   |   1   |   2   ||   21  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      "\n",
      ":: problems summary ::\n",
      ":::: ERRORS\n",
      "\tunknown resolver null\n",
      "\n",
      "\n",
      ":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ce28daa3-3029-4a04-ac2d-9eb62b97621d\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 21 already retrieved (0kB/17ms)\n",
      "24/04/24 10:10:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/tmp/ipykernel_2270541/4135544272.py:22: DeprecationWarning: Call to deprecated function registerAll (Deprecated since 1.4.1, use SedonaContext.create() instead.).\n",
      "  SedonaRegistrator.registerAll(spark)\n",
      "/s/chopin/a/grad/flarrieu/.local/lib/python3.9/site-packages/sedona/register/geo_registrator.py:45: DeprecationWarning: Call to deprecated function register (Deprecated since 1.4.1, use SedonaContext.create() instead.).\n",
      "  cls.register(spark)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('GeoSpatialQueries_Freddy') \\\n",
    "    .master('spark://columbus-oh.cs.colostate.edu:30800') \\\n",
    "    .config(\"spark.yarn.resourcemanager.address\", \"columbia.cs.colostate.edu:30799\") \\\n",
    "    .config(\"spark.executor.memory\", \"3g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"512m\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", True) \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"500m\") \\\n",
    "    .config(\"spark.serializer\", KryoSerializer.getName) \\\n",
    "    .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) \\\n",
    "    .config('spark.jars.packages',\n",
    "            'org.apache.sedona:sedona-spark-3.5_2.12:1.5.1,'\n",
    "            'org.datasyslab:geotools-wrapper:1.5.1-28.2') \\\n",
    "    .config('spark.jars.repositories', 'https://artifacts.unidata.ucar.edu/repository/unidata-all') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to DEBUG\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "sedona = SedonaContext.create(spark)\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# create a logger\n",
    "logger = spark._jvm.org.apache.log4j.LogManager.getLogger(__name__)\n",
    "logger.info(\"Pyspark initialized...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary module from py4j to interact with JVM\n",
    "from py4j.java_gateway import java_import\n",
    "\n",
    "# Import the Path class from Hadoop. This class is used to handle file paths in Hadoop.\n",
    "java_import(spark._jvm, 'org.apache.hadoop.fs.Path')\n",
    "\n",
    "fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "\n",
    "def get_files_recursive(path):\n",
    "    file_status_arr = fs.listStatus(spark._jvm.Path(path))\n",
    "    file_paths = []\n",
    "    \n",
    "    for file_status in file_status_arr:\n",
    "        if file_status.isDirectory():\n",
    "            file_paths += get_files_recursive(file_status.getPath().toString())\n",
    "        elif file_status.getPath().getName().endswith(('.geojson')):\n",
    "            file_paths.append(file_status.getPath().toString())\n",
    "    \n",
    "    print(file_paths)\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(df: DataFrame, path: str):\n",
    "    df.write.csv(path=path, mode='append', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(df: DataFrame, path: str):\n",
    "    df.write.csv(path=path, mode='append', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_to_df(file_name: str): \n",
    "    data_directory = \"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/\"\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "\n",
    "    geojson_schema =  \"type string, crs string, totalFeatures long, features array<struct<type string, geometry string, properties map<string, string>>>\"\n",
    "\n",
    "    df = spark.read.schema(geojson_schema).json(data_directory + file_name, multiLine=True)\n",
    "    \n",
    "    df = (df\n",
    "        .select(explode(\"features\").alias(\"features\"))\n",
    "        .select(\"features.*\")\n",
    "        .withColumn(\"geometry\", expr(\"ST_GeomFromGeoJSON(geometry)\"))\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_df(df_parent: DataFrame, subject, relationship, object):\n",
    "    df_edges = df_parent.withColumn(\"Subject\", subject) \\\n",
    "        .withColumn(\"Relationship\", relationship) \\\n",
    "        .withColumn(\"Object\", object) \\\n",
    "        .select(\"Subject\", \"Relationship\", \"Object\")\n",
    "    return df_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_df(df_edges: DataFrame, type):\n",
    "    nodes_subject = df_edges.select(col(\"Subject\").alias(\"Node_ID\")).distinct()\n",
    "    nodes_object = df_edges.select(col(\"Object\").alias(\"Node_ID\")).distinct()\n",
    "\n",
    "    nodes_df = nodes_subject.union(nodes_object).distinct()\n",
    "\n",
    "    nodes_df = nodes_df.withColumn(\"Type\", type)\n",
    "    \n",
    "    return nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relationships_point(df_parent: DataFrame, df_child: DataFrame, ):\n",
    "    df_parent = df_parent.withColumnRenamed(\"geometry\", \"parent_geometry\")\n",
    "    df_child = df_child.withColumnRenamed(\"geometry\", \"child_geometry\")\n",
    "    df_parent = df_parent.withColumnRenamed(\"properties\", \"parent_properties\")\n",
    "    df_child = df_child.withColumnRenamed(\"properties\", \"child_properties\")\n",
    "\n",
    "    df_parent.createOrReplaceTempView(\"parents\")\n",
    "    df_child.createOrReplaceTempView(\"children\")\n",
    "\n",
    "    df_country_continent_contains = spark.sql(\"\"\"\n",
    "        SELECT *\n",
    "        FROM parents, children\n",
    "        WHERE ST_Contains(parent_geometry, ST_Centroid(child_geometry))\n",
    "    \"\"\")\n",
    "\n",
    "    return df_country_continent_contains.select(\"parent_geometry\", \"child_geometry\", \"parent_properties\", \"child_properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_relationships_geometry(df_parent: DataFrame, df_child: DataFrame, ):\n",
    "    df_parent = df_parent.withColumnRenamed(\"geometry\", \"parent_geometry\")\n",
    "    df_child = df_child.withColumnRenamed(\"geometry\", \"child_geometry\")\n",
    "    df_parent = df_parent.withColumnRenamed(\"properties\", \"parent_properties\")\n",
    "    df_child = df_child.withColumnRenamed(\"properties\", \"child_properties\")\n",
    "\n",
    "    df_parent.createOrReplaceTempView(\"parents\")\n",
    "    df_child.createOrReplaceTempView(\"children\")\n",
    "\n",
    "    df_country_continent_contains = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            p.parent_geometry, \n",
    "            c.child_geometry, \n",
    "            p.parent_properties, \n",
    "            c.child_properties,\n",
    "            CASE \n",
    "                WHEN ST_Contains(p.parent_geometry, ST_Centroid(c.child_geometry)) THEN 'Contains'\n",
    "                WHEN ST_DWithin(p.parent_geometry, ST_Centroid(c.child_geometry), 100) THEN 'Within 100m'\n",
    "                WHEN ST_Touches(p.parent_geometry, c.child_geometry) THEN 'Touches'\n",
    "                WHEN ST_Intersects(p.parent_geometry, c.child_geometry) THEN 'Intersects'\n",
    "            END AS relationship_type\n",
    "        FROM parents p, children c\n",
    "        WHERE ST_Contains(p.parent_geometry, ST_Centroid(c.child_geometry))\n",
    "        OR ST_DWithin(p.parent_geometry, ST_Centroid(c.child_geometry), 100)\n",
    "        OR ST_Touches(p.parent_geometry, c.child_geometry)\n",
    "        OR ST_Intersects(p.parent_geometry, c.child_geometry)\n",
    "    \"\"\")\n",
    "\n",
    "    return df_country_continent_contains.select(\"parent_geometry\", \"child_geometry\", \"parent_properties\", \"child_properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from functools import reduce\n",
    "\n",
    "def union_all(dfs_dict):\n",
    "    dfs = list(dfs_dict.values())\n",
    "    if dfs:\n",
    "        return reduce(DataFrame.unionByName, dfs)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resolution(resolution_directory: str):\n",
    "    resolution_dataframes = {}\n",
    "    files_directory = f\"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/{resolution_directory}/\"\n",
    "\n",
    "    files = get_files_recursive(files_directory)\n",
    "\n",
    "    for file_path in files:\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        \n",
    "        print(f\"Processing file: {file_path}\")\n",
    "\n",
    "        geojsonSchema = \"type string, crs string, totalFeatures long, features array<struct<type string, geometry string, properties map<string, string>>>\"\n",
    "        \n",
    "        df = spark.read.schema(geojsonSchema).json(file_path, multiLine=True)\n",
    "        \n",
    "        df = (df\n",
    "            .select(F.explode(\"features\").alias(\"features\"))\n",
    "            .select(\"features.*\")\n",
    "            .withColumn(\"geometry\", F.expr(\"ST_GeomFromGeoJSON(geometry)\"))\n",
    "            )\n",
    "        \n",
    "        resolution_dataframes[file_name] = df\n",
    "    return resolution_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_at_resolution(df_dataset: DataFrame, dataset:str, resolutions_dir: str, resolution_prefix: str, dataset_unique_id: str, resolution_unique_id: str, verbose=False):\n",
    "    resolutions_dataframes = load_resolution(resolutions_dir)\n",
    "    dataset_prefix = lit(dataset + \"_\")\n",
    "    final_resolution_edges = {}\n",
    "    final_resolution_nodes = {}\n",
    "\n",
    "    for resolutions_file_name, df_resolutions in resolutions_dataframes.items():\n",
    "        resolutions = resolutions_file_name.replace('.geojson', '')\n",
    "        print(resolutions)\n",
    "\n",
    "        df_resolutions_contain_dataset = create_relationships_point(df_resolutions, df_dataset)\n",
    "        \n",
    "        df_dataset_isPartOf_resolution_edges = create_edge_df(df_resolutions_contain_dataset, concat(lit(dataset_prefix), col(dataset_unique_id), lit(\"isPartOf\"), concat(lit(resolution_prefix), col(resolution_unique_id)))\n",
    "        if verbose: df_dataset_isPartOf_resolution_edges.show(n=1, truncate=False)\n",
    "        final_resolution_edges[f'DatasetIsPartOf{resolutions}Resolutions'] = df_dataset_isPartOf_resolution_edges\n",
    "\n",
    "        df_resolution_contains_dataset_edges = create_edge_df(df_resolutions_contain_dataset, concat(lit(resolution_prefix), col(resolution_unique_id)), lit(\"Contains\"), concat(lit(dataset_prefix), col(dataset_unique_id)))\n",
    "        if verbose: df_resolution_contains_dataset_edges.show(n=1, truncate=False)\n",
    "        final_resolution_edges[f'{resolutions}ResolutionContainsDataset'] = df_resolution_contains_dataset_edges\n",
    "\n",
    "        df_nodes = create_node_df(df_dataset_isPartOf_resolution_edges, lit(dataset))\n",
    "        df_nodes = df_nodes.filter(~col(\"Node_ID\").contains(f\"{resolution_prefix}_\"))\n",
    "        final_resolution_nodes[f'{resolutions}Resolutions'] = df_nodes\n",
    "        if verbose: df_nodes.show(truncate=False)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_dataset(df_dataset: DataFrame, dataset: str, resolution: str, dataset_unique_id: str, verbose=False):\n",
    "    if resolution == 'County':\n",
    "        pass\n",
    "    elif resolution == 'Tract':\n",
    "        pass\n",
    "    elif resolution == 'BlockGroup':\n",
    "        return integrate_at_resolution(df_dataset, dataset, \"BlocksByState\", \"BlockGroup_\", dataset_unique_id, \"parent_properties.GEOID\", verbose)\n",
    "    else:\n",
    "        print(resolution + \" isn't a resolution try: County, Tract, BlockGroup\")\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_edges_path = \"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/graph/BaseEdges.csv\"\n",
    "base_nodes_path = \"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/graph/BaseNodes.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Get Blocks (Leaf Nodes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Alabama.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Alaska.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/AmericanSamoa.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Arizona.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Arkansas.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/California.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Colorado.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/CommonwealthoftheNorthernMarianaIslands.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Connecticut.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Delaware.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/DistrictofColumbia.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Florida.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Georgia.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Guam.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Hawaii.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Idaho.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Illinois.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Indiana.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Iowa.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Kansas.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Kentucky.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Louisiana.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Maine.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Maryland.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Massachusetts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Michigan.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Minnesota.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Mississippi.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Missouri.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Montana.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Nebraska.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Nevada.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewHampshire.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewJersey.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewMexico.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewYork.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NorthCarolina.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NorthDakota.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Ohio.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Oklahoma.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Oregon.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Pennsylvania.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/PuertoRico.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/RhodeIsland.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/SouthCarolina.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/SouthDakota.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Tennessee.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Texas.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/UnitedStatesVirginIslands.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Utah.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Vermont.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Virginia.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Washington.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/WestVirginia.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Wisconsin.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Wyoming.geojson']\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Alabama.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Alaska.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/AmericanSamoa.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Arizona.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Arkansas.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/California.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Colorado.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/CommonwealthoftheNorthernMarianaIslands.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Connecticut.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Delaware.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/DistrictofColumbia.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Florida.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Georgia.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Guam.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Hawaii.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Idaho.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Illinois.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Indiana.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Iowa.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Kansas.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Kentucky.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Louisiana.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Maine.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Maryland.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Massachusetts.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Michigan.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Minnesota.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Mississippi.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Missouri.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Montana.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Nebraska.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Nevada.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewHampshire.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewJersey.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewMexico.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewYork.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NorthCarolina.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NorthDakota.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Ohio.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Oklahoma.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Oregon.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Pennsylvania.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/PuertoRico.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/RhodeIsland.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/SouthCarolina.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/SouthDakota.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Tennessee.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Texas.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/UnitedStatesVirginIslands.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Utah.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Vermont.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Virginia.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Washington.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/WestVirginia.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Wisconsin.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Wyoming.geojson\n"
     ]
    }
   ],
   "source": [
    "blocks_dataframes = {}\n",
    "files_directory = \"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/\"\n",
    "\n",
    "files = get_files_recursive(files_directory)\n",
    "\n",
    "for file_path in files:\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    \n",
    "    print(f\"Processing file: {file_path}\")\n",
    "\n",
    "    geojsonSchema = \"type string, crs string, totalFeatures long, features array<struct<type string, geometry string, properties map<string, string>>>\"\n",
    "    \n",
    "    df = spark.read.schema(geojsonSchema).json(file_path, multiLine=True)\n",
    "    \n",
    "    df = (df\n",
    "        .select(F.explode(\"features\").alias(\"features\"))\n",
    "        .select(\"features.*\")\n",
    "        .withColumn(\"geometry\", F.expr(\"ST_GeomFromGeoJSON(geometry)\"))\n",
    "        )\n",
    "    \n",
    "    blocks_dataframes[file_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get County Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/AlabamaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/AlaskaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/AmericanSamoaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/ArizonaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/ArkansasCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/CaliforniaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/ColoradoCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/CommonwealthoftheNorthernMarianaIslandsCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/ConnecticutCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/DelawareCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/DistrictofColumbiaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/FloridaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/GeorgiaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/GuamCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/HawaiiCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/IdahoCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/IllinoisCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/IndianaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/IowaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/KansasCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/KentuckyCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/LouisianaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/MaineCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/MarylandCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/MassachusettsCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/MichiganCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/MinnesotaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/MississippiCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/MissouriCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/MontanaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/NebraskaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/NevadaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/NewHampshireCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/NewJerseyCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/NewMexicoCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/NewYorkCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/NorthCarolinaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/NorthDakotaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/OhioCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/OklahomaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/OregonCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/PennsylvaniaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/PuertoRicoCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/RhodeIslandCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/SouthCarolinaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/SouthDakotaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/TennesseeCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/TexasCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/UnitedStatesVirginIslandsCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/UtahCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/VermontCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/VirginiaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/WashingtonCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/WestVirginiaCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/WisconsinCounties.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/WyomingCounties.geojson']\n",
      "Processing file: AlabamaCounties.geojson\n",
      "Processing file: AlaskaCounties.geojson\n",
      "Processing file: AmericanSamoaCounties.geojson\n",
      "Processing file: ArizonaCounties.geojson\n",
      "Processing file: ArkansasCounties.geojson\n",
      "Processing file: CaliforniaCounties.geojson\n",
      "Processing file: ColoradoCounties.geojson\n",
      "Processing file: CommonwealthoftheNorthernMarianaIslandsCounties.geojson\n",
      "Processing file: ConnecticutCounties.geojson\n",
      "Processing file: DelawareCounties.geojson\n",
      "Processing file: DistrictofColumbiaCounties.geojson\n",
      "Processing file: FloridaCounties.geojson\n",
      "Processing file: GeorgiaCounties.geojson\n",
      "Processing file: GuamCounties.geojson\n",
      "Processing file: HawaiiCounties.geojson\n",
      "Processing file: IdahoCounties.geojson\n",
      "Processing file: IllinoisCounties.geojson\n",
      "Processing file: IndianaCounties.geojson\n",
      "Processing file: IowaCounties.geojson\n",
      "Processing file: KansasCounties.geojson\n",
      "Processing file: KentuckyCounties.geojson\n",
      "Processing file: LouisianaCounties.geojson\n",
      "Processing file: MaineCounties.geojson\n",
      "Processing file: MarylandCounties.geojson\n",
      "Processing file: MassachusettsCounties.geojson\n",
      "Processing file: MichiganCounties.geojson\n",
      "Processing file: MinnesotaCounties.geojson\n",
      "Processing file: MississippiCounties.geojson\n",
      "Processing file: MissouriCounties.geojson\n",
      "Processing file: MontanaCounties.geojson\n",
      "Processing file: NebraskaCounties.geojson\n",
      "Processing file: NevadaCounties.geojson\n",
      "Processing file: NewHampshireCounties.geojson\n",
      "Processing file: NewJerseyCounties.geojson\n",
      "Processing file: NewMexicoCounties.geojson\n",
      "Processing file: NewYorkCounties.geojson\n",
      "Processing file: NorthCarolinaCounties.geojson\n",
      "Processing file: NorthDakotaCounties.geojson\n",
      "Processing file: OhioCounties.geojson\n",
      "Processing file: OklahomaCounties.geojson\n",
      "Processing file: OregonCounties.geojson\n",
      "Processing file: PennsylvaniaCounties.geojson\n",
      "Processing file: PuertoRicoCounties.geojson\n",
      "Processing file: RhodeIslandCounties.geojson\n",
      "Processing file: SouthCarolinaCounties.geojson\n",
      "Processing file: SouthDakotaCounties.geojson\n",
      "Processing file: TennesseeCounties.geojson\n",
      "Processing file: TexasCounties.geojson\n",
      "Processing file: UnitedStatesVirginIslandsCounties.geojson\n",
      "Processing file: UtahCounties.geojson\n",
      "Processing file: VermontCounties.geojson\n",
      "Processing file: VirginiaCounties.geojson\n",
      "Processing file: WashingtonCounties.geojson\n",
      "Processing file: WestVirginiaCounties.geojson\n",
      "Processing file: WisconsinCounties.geojson\n",
      "Processing file: WyomingCounties.geojson\n"
     ]
    }
   ],
   "source": [
    "counties_dataframes = {}\n",
    "files_directory = \"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/CountiesByState/\"\n",
    "files = get_files_recursive(files_directory)\n",
    "\n",
    "for file_path in files:\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    \n",
    "    # Print the file path\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "\n",
    "    geojsonSchema = \"type string, crs string, totalFeatures long, features array<struct<type string, geometry string, properties map<string, string>>>\"\n",
    "\n",
    "    df = spark.read.schema(geojsonSchema).json(file_path, multiLine=True)\n",
    "    \n",
    "    df = (df\n",
    "        .select(F.explode(\"features\").alias(\"features\"))\n",
    "        .select(\"features.*\")\n",
    "        .withColumn(\"geometry\", F.expr(\"ST_GeomFromGeoJSON(geometry)\"))\n",
    "        )\n",
    "    \n",
    "    counties_dataframes[file_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Tract Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/AlabamaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/AlaskaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/AmericanSamoaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/ArizonaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/ArkansasTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/CaliforniaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/ColoradoTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/CommonwealthoftheNorthernMarianaIslandsTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/ConnecticutTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/DelawareTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/DistrictofColumbiaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/FloridaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/GeorgiaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/GuamTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/HawaiiTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/IdahoTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/IllinoisTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/IndianaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/IowaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/KansasTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/KentuckyTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/LouisianaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/MaineTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/MarylandTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/MassachusettsTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/MichiganTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/MinnesotaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/MississippiTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/MissouriTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/MontanaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/NebraskaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/NevadaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/NewHampshireTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/NewJerseyTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/NewMexicoTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/NewYorkTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/NorthCarolinaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/NorthDakotaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/OhioTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/OklahomaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/OregonTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/PennsylvaniaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/PuertoRicoTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/RhodeIslandTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/SouthCarolinaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/SouthDakotaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/TennesseeTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/TexasTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/UnitedStatesVirginIslandsTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/UtahTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/VermontTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/VirginiaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/WashingtonTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/WestVirginiaTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/WisconsinTracts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/WyomingTracts.geojson']\n",
      "Processing file: AlabamaTracts.geojson\n",
      "Processing file: AlaskaTracts.geojson\n",
      "Processing file: AmericanSamoaTracts.geojson\n",
      "Processing file: ArizonaTracts.geojson\n",
      "Processing file: ArkansasTracts.geojson\n",
      "Processing file: CaliforniaTracts.geojson\n",
      "Processing file: ColoradoTracts.geojson\n",
      "Processing file: CommonwealthoftheNorthernMarianaIslandsTracts.geojson\n",
      "Processing file: ConnecticutTracts.geojson\n",
      "Processing file: DelawareTracts.geojson\n",
      "Processing file: DistrictofColumbiaTracts.geojson\n",
      "Processing file: FloridaTracts.geojson\n",
      "Processing file: GeorgiaTracts.geojson\n",
      "Processing file: GuamTracts.geojson\n",
      "Processing file: HawaiiTracts.geojson\n",
      "Processing file: IdahoTracts.geojson\n",
      "Processing file: IllinoisTracts.geojson\n",
      "Processing file: IndianaTracts.geojson\n",
      "Processing file: IowaTracts.geojson\n",
      "Processing file: KansasTracts.geojson\n",
      "Processing file: KentuckyTracts.geojson\n",
      "Processing file: LouisianaTracts.geojson\n",
      "Processing file: MaineTracts.geojson\n",
      "Processing file: MarylandTracts.geojson\n",
      "Processing file: MassachusettsTracts.geojson\n",
      "Processing file: MichiganTracts.geojson\n",
      "Processing file: MinnesotaTracts.geojson\n",
      "Processing file: MississippiTracts.geojson\n",
      "Processing file: MissouriTracts.geojson\n",
      "Processing file: MontanaTracts.geojson\n",
      "Processing file: NebraskaTracts.geojson\n",
      "Processing file: NevadaTracts.geojson\n",
      "Processing file: NewHampshireTracts.geojson\n",
      "Processing file: NewJerseyTracts.geojson\n",
      "Processing file: NewMexicoTracts.geojson\n",
      "Processing file: NewYorkTracts.geojson\n",
      "Processing file: NorthCarolinaTracts.geojson\n",
      "Processing file: NorthDakotaTracts.geojson\n",
      "Processing file: OhioTracts.geojson\n",
      "Processing file: OklahomaTracts.geojson\n",
      "Processing file: OregonTracts.geojson\n",
      "Processing file: PennsylvaniaTracts.geojson\n",
      "Processing file: PuertoRicoTracts.geojson\n",
      "Processing file: RhodeIslandTracts.geojson\n",
      "Processing file: SouthCarolinaTracts.geojson\n",
      "Processing file: SouthDakotaTracts.geojson\n",
      "Processing file: TennesseeTracts.geojson\n",
      "Processing file: TexasTracts.geojson\n",
      "Processing file: UnitedStatesVirginIslandsTracts.geojson\n",
      "Processing file: UtahTracts.geojson\n",
      "Processing file: VermontTracts.geojson\n",
      "Processing file: VirginiaTracts.geojson\n",
      "Processing file: WashingtonTracts.geojson\n",
      "Processing file: WestVirginiaTracts.geojson\n",
      "Processing file: WisconsinTracts.geojson\n",
      "Processing file: WyomingTracts.geojson\n"
     ]
    }
   ],
   "source": [
    "tractss_dataframes = {}\n",
    "files_directory = \"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/TractsByState/\"\n",
    "files = get_files_recursive(files_directory)\n",
    "\n",
    "for file_path in files:\n",
    "    file_name = file_path.split('/')[-1]\n",
    "    \n",
    "    # Print the file path\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "\n",
    "    geojsonSchema = \"type string, crs string, totalFeatures long, features array<struct<type string, geometry string, properties map<string, string>>>\"\n",
    "\n",
    "    df = spark.read.schema(geojsonSchema).json(file_path, multiLine=True)\n",
    "    \n",
    "    df = (df\n",
    "        .select(F.explode(\"features\").alias(\"features\"))\n",
    "        .select(\"features.*\")\n",
    "        .withColumn(\"geometry\", F.expr(\"ST_GeomFromGeoJSON(geometry)\"))\n",
    "        )\n",
    "    \n",
    "    counties_dataframes[file_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_nodes(df_dataset: DataFrame, unique_identifier:str , dataset: str, column_mappings: dict):\n",
    "    # Generate Node_ID using a prefix from the dataset name and a unique identifier\n",
    "    dataset_prefix = lit(dataset + \"_\")\n",
    "    df_nodes = df_dataset.withColumn(\"Node_ID\", concat(dataset_prefix, col(\"properties.NAME\")))\n",
    "    \n",
    "    # Map all specified columns\n",
    "    for new_col, old_col in column_mappings.items():\n",
    "        if new_col == 'Type':\n",
    "            # If the column is 'Type', use a literal value instead of a column reference\n",
    "            df_nodes = df_nodes.withColumn(new_col, lit(old_col))\n",
    "        elif new_col != \"Node_ID\":  # Node_ID is already handled\n",
    "            df_nodes = df_nodes.withColumn(new_col, col(old_col))\n",
    "    \n",
    "    # Handle geometry separately, converting it to GeoJSON (assuming the geometry column is named 'geometry')\n",
    "    if \"geometry\" in df_dataset.columns:\n",
    "        df_nodes = df_nodes.withColumn(\"geometry\", expr(\"ST_AsGeoJSON(geometry)\"))\n",
    "    \n",
    "    # # Drop all original columns except those transformed to new ones\n",
    "    df_nodes = df_nodes.drop(\"properties\")\n",
    "\n",
    "    # Display the first few rows of the resultant DataFrame\n",
    "    df_nodes.show(5, truncate=False)\n",
    "    \n",
    "    return df_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GeneralManufacturingFacilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'GeneralManufacturingFacilities'\n",
    "dataset_nodes_path = f\"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/dataset_graphs/{dataset}Nodes.csv\"\n",
    "dataset_edges_path = f\"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/dataset_graphs/{dataset}Edges.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: GeneralManufacturingFacilities.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|type   |geometry                      |properties                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "+-------+------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Feature|POINT (144.7883065 13.4912295)|{OBJECTID -> 3, UNIQUE_ID -> N/A, NAME -> JWS REFRIGERATION & AIR CONDITIONING, PHONE -> (671) 646-7662, FAX -> NOT AVAILABLE, ADDRESS -> 290 TUN JOSE SALAS STREET, ADDRESS2 -> SUITE A, CITY -> TAMUNING, STATE -> GU, ZIP -> 96913, ZIP4 -> N/A, COUNTY -> GUAM, FIPS -> 66010, MADDRESS -> 290 TUN JOSE SALAS STREET, MCITY -> TAMUNING, MSTATE -> GU, MZIP -> 96913, MZIP4 -> N/A, DIRECTIONS -> NOT AVAILABLE, GEOPREC -> BLOCKFACE, EMP -> 0, PRODUCT -> REFRIGERATION AND AIR-CONDITIONING, SIC -> 3585, SIC2 -> 2542, SIC3 -> N/A, SIC4 -> N/A, NAICS -> N/A, NAICSDESCR -> NOT AVAILABLE, WEB -> WWW.JWSGUAM.COM, LONGITUDE -> 144.7883065, LATITUDE -> 13.4912295}|\n",
      "+-------+------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_dataset = get_file_to_df(f'{dataset}.geojson')\n",
    "df_dataset.show(n=1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/24 11:08:32 ERROR TaskSchedulerImpl: Lost executor 12 on 129.82.44.141: Command exited with code 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------------------------------------------------------------+-------------------------------------------------------------------+------------------------------------+--------------+--------------+-----------------------------+--------+-----+-----+-----------------+\n",
      "|Type                          |geometry                                                     |Node_ID                                                            |Name                                |Phone         |Fax           |Address                      |City    |State|Zip  |County           |\n",
      "+------------------------------+-------------------------------------------------------------+-------------------------------------------------------------------+------------------------------------+--------------+--------------+-----------------------------+--------+-----+-----+-----------------+\n",
      "|GeneralManufacturingFacilities|{\"type\":\"Point\",\"coordinates\":[144.7883065,13.4912295]}      |GeneralManufacturingFacilities_JWS REFRIGERATION & AIR CONDITIONING|JWS REFRIGERATION & AIR CONDITIONING|(671) 646-7662|NOT AVAILABLE |290 TUN JOSE SALAS STREET    |TAMUNING|GU   |96913|GUAM             |\n",
      "|GeneralManufacturingFacilities|{\"type\":\"Point\",\"coordinates\":[-166.5517697,53.8795107]}     |GeneralManufacturingFacilities_UNISEA, INC.                        |UNISEA, INC.                        |(907) 581-1258|(907) 581-7228|88 SALMON WAY                |UNALASKA|AK   |99685|ALEUTIANS WEST   |\n",
      "|GeneralManufacturingFacilities|{\"type\":\"Point\",\"coordinates\":[-152.391531,57.7904544000001]}|GeneralManufacturingFacilities_GLOBAL SEAFOODS NORTH AMERICA, LLC  |GLOBAL SEAFOODS NORTH AMERICA, LLC  |(907) 486-0355|(907) 486-0253|800 EAST MARINE WAY          |KODIAK  |AK   |99615|KODIAK ISLAND    |\n",
      "|GeneralManufacturingFacilities|{\"type\":\"Point\",\"coordinates\":[-151.2284248,60.5515696]}     |GeneralManufacturingFacilities_SALAMATOF SEAFOODS, INC.            |SALAMATOF SEAFOODS, INC.            |(907) 283-7000|(907) 283-8499|MILE 1 1/2 BRIDGE ACCESS ROAD|KENAI   |AK   |99611|KENAI PENINSULA  |\n",
      "|GeneralManufacturingFacilities|{\"type\":\"Point\",\"coordinates\":[-149.3048435,61.5871132]}     |GeneralManufacturingFacilities_MAT-SU VALLEY FRONTIERSMAN, THE     |MAT-SU VALLEY FRONTIERSMAN, THE     |(907) 352-2250|(907) 352-2277|5751 EAST MAYFLOWER COURT    |WASILLA |AK   |99654|MATANUSKA-SUSITNA|\n",
      "+------------------------------+-------------------------------------------------------------+-------------------------------------------------------------------+------------------------------------+--------------+--------------+-----------------------------+--------+-----+-----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "# \"properties\": {\n",
    "#     \"OBJECTID\": 3,\n",
    "#     \"UNIQUE_ID\": \"N/A\",\n",
    "#     \"NAME\": \"JWS REFRIGERATION & AIR CONDITIONING\",\n",
    "#     \"PHONE\": \"(671) 646-7662\",\n",
    "#     \"FAX\": \"NOT AVAILABLE\",\n",
    "#     \"ADDRESS\": \"290 TUN JOSE SALAS STREET\",\n",
    "#     \"ADDRESS2\": \"SUITE A\",\n",
    "#     \"CITY\": \"TAMUNING\",\n",
    "#     \"STATE\": \"GU\",\n",
    "#     \"ZIP\": \"96913\",\n",
    "#     \"ZIP4\": \"N/A\",\n",
    "#     \"COUNTY\": \"GUAM\",\n",
    "#     \"FIPS\": \"66010\",\n",
    "#     \"MADDRESS\": \"290 TUN JOSE SALAS STREET\",\n",
    "#     \"MCITY\": \"TAMUNING\",\n",
    "#     \"MSTATE\": \"GU\",\n",
    "#     \"MZIP\": \"96913\",\n",
    "#     \"MZIP4\": \"N/A\",\n",
    "#     \"DIRECTIONS\": \"NOT AVAILABLE\",\n",
    "#     \"GEOPREC\": \"BLOCKFACE\",\n",
    "#     \"EMP\": 0,\n",
    "#     \"PRODUCT\": \"REFRIGERATION AND AIR-CONDITIONING\",\n",
    "#     \"SIC\": \"3585\",\n",
    "#     \"SIC2\": \"2542\",\n",
    "#     \"SIC3\": \"N/A\",\n",
    "#     \"SIC4\": \"N/A\",\n",
    "#     \"NAICS\": \"N/A\",\n",
    "#     \"NAICSDESCR\": \"NOT AVAILABLE\",\n",
    "#     \"WEB\": \"WWW.JWSGUAM.COM\",\n",
    "#     \"LONGITUDE\": 144.7883065,\n",
    "#     \"LATITUDE\": 13.4912295\n",
    "# }\n",
    "\n",
    "\n",
    "general_mfg_mappings = {\n",
    "    \"Type\": dataset,\n",
    "    \"Name\": \"properties.NAME\",\n",
    "    \"Phone\": \"properties.PHONE\",\n",
    "    \"Fax\": \"properties.FAX\",\n",
    "    \"Address\": \"properties.ADDRESS\",\n",
    "    \"City\": \"properties.CITY\",\n",
    "    \"State\": \"properties.STATE\",\n",
    "    \"Zip\": \"properties.ZIP\",\n",
    "    \"County\": \"properties.COUNTY\"\n",
    "}\n",
    "\n",
    "df_nodes = create_dataset_nodes(df_dataset, \"properties.NAME\", dataset, general_mfg_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv(df_nodes, dataset_nodes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Alabama.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Alaska.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/AmericanSamoa.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Arizona.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Arkansas.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/California.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Colorado.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/CommonwealthoftheNorthernMarianaIslands.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Connecticut.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Delaware.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/DistrictofColumbia.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Florida.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Georgia.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Guam.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Hawaii.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Idaho.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Illinois.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Indiana.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Iowa.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Kansas.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Kentucky.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Louisiana.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Maine.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Maryland.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Massachusetts.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Michigan.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Minnesota.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Mississippi.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Missouri.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Montana.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Nebraska.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Nevada.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewHampshire.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewJersey.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewMexico.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewYork.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NorthCarolina.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NorthDakota.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Ohio.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Oklahoma.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Oregon.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Pennsylvania.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/PuertoRico.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/RhodeIsland.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/SouthCarolina.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/SouthDakota.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Tennessee.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Texas.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/UnitedStatesVirginIslands.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Utah.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Vermont.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Virginia.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Washington.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/WestVirginia.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Wisconsin.geojson', 'hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Wyoming.geojson']\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Alabama.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Alaska.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/AmericanSamoa.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Arizona.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Arkansas.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/California.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Colorado.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/CommonwealthoftheNorthernMarianaIslands.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Connecticut.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Delaware.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/DistrictofColumbia.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Florida.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Georgia.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Guam.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Hawaii.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Idaho.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Illinois.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Indiana.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Iowa.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Kansas.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Kentucky.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Louisiana.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Maine.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Maryland.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Massachusetts.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Michigan.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Minnesota.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Mississippi.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Missouri.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Montana.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Nebraska.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Nevada.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewHampshire.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewJersey.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewMexico.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NewYork.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NorthCarolina.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/NorthDakota.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Ohio.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Oklahoma.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Oregon.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Pennsylvania.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/PuertoRico.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/RhodeIsland.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/SouthCarolina.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/SouthDakota.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Tennessee.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Texas.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/UnitedStatesVirginIslands.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Utah.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Vermont.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Virginia.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Washington.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/WestVirginia.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Wisconsin.geojson\n",
      "Processing file: hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/input/BlocksByState/Wyoming.geojson\n",
      "Alabama\n",
      "Creating isPartOfEdges:  Column<'concat(GeneralManufacturingFacilities_, properties.NAME)'>\n"
     ]
    },
    {
     "ename": "PySparkTypeError",
     "evalue": "[NOT_ITERABLE] Column is not iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mintegrate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBlockGroup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproperties.NAME\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [88]\u001b[0m, in \u001b[0;36mintegrate_dataset\u001b[0;34m(df_dataset, dataset, resolution, dataset_unique_id, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m resolution \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlockGroup\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mintegrate_at_resolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBlocksByState\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBlockGroup_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_unique_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparent_properties.GEOID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(resolution \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt a resolution try: County, Tract, BlockGroup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36mintegrate_at_resolution\u001b[0;34m(df_dataset, dataset, resolutions_dir, resolution_prefix, dataset_unique_id, resolution_unique_id, verbose)\u001b[0m\n\u001b[1;32m     11\u001b[0m df_resolutions_contain_dataset \u001b[38;5;241m=\u001b[39m create_relationships_point(df_resolutions, df_dataset)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating isPartOfEdges: \u001b[39m\u001b[38;5;124m\"\u001b[39m, concat(lit(dataset_prefix), col(dataset_unique_id)))\n\u001b[0;32m---> 14\u001b[0m df_dataset_isPartOf_resolution_edges \u001b[38;5;241m=\u001b[39m create_edge_df(df_resolutions_contain_dataset, concat(lit(dataset_prefix), \u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_unique_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m), lit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misPartOf\u001b[39m\u001b[38;5;124m\"\u001b[39m), concat(lit(resolution_prefix), col(resolution_unique_id)))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose: df_dataset_isPartOf_resolution_edges\u001b[38;5;241m.\u001b[39mshow(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m final_resolution_edges[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasetIsPartOf\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolutions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mResolutions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_dataset_isPartOf_resolution_edges\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/sql/utils.py:174\u001b[0m, in \u001b[0;36mtry_remote_functions.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(functions, f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/sql/functions.py:223\u001b[0m, in \u001b[0;36mcol\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@try_remote_functions\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcol\u001b[39m(col: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Column:\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    Returns a :class:`~pyspark.sql.Column` based on the given column name.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124;03m    Column<'x'>\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_invoke_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/sql/functions.py:97\u001b[0m, in \u001b[0;36m_invoke_function\u001b[0;34m(name, *args)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     96\u001b[0m jf \u001b[38;5;241m=\u001b[39m _get_jvm_function(name, SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context)\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[43mjf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/python-env/py39/lib/python3.9/site-packages/py4j/java_gateway.py:1313\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1313\u001b[0m     args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m     command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m         args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m         proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m/usr/local/python-env/py39/lib/python3.9/site-packages/py4j/java_gateway.py:1277\u001b[0m, in \u001b[0;36mJavaMember._build_args\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_build_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverters) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1277\u001b[0m         (new_args, temp_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1279\u001b[0m         new_args \u001b[38;5;241m=\u001b[39m args\n",
      "File \u001b[0;32m/usr/local/python-env/py39/lib/python3.9/site-packages/py4j/java_gateway.py:1264\u001b[0m, in \u001b[0;36mJavaMember._get_args\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m converter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39mconverters:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter\u001b[38;5;241m.\u001b[39mcan_convert(arg):\n\u001b[0;32m-> 1264\u001b[0m         temp_arg \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m         temp_args\u001b[38;5;241m.\u001b[39mappend(temp_arg)\n\u001b[1;32m   1266\u001b[0m         new_args\u001b[38;5;241m.\u001b[39mappend(temp_arg)\n",
      "File \u001b[0;32m/usr/local/python-env/py39/lib/python3.9/site-packages/py4j/java_collections.py:510\u001b[0m, in \u001b[0;36mListConverter.convert\u001b[0;34m(self, object, gateway_client)\u001b[0m\n\u001b[1;32m    508\u001b[0m ArrayList \u001b[38;5;241m=\u001b[39m JavaClass(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava.util.ArrayList\u001b[39m\u001b[38;5;124m\"\u001b[39m, gateway_client)\n\u001b[1;32m    509\u001b[0m java_list \u001b[38;5;241m=\u001b[39m ArrayList()\n\u001b[0;32m--> 510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    511\u001b[0m     java_list\u001b[38;5;241m.\u001b[39madd(element)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m java_list\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/sql/column.py:718\u001b[0m, in \u001b[0;36mColumn.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    719\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_ITERABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m, message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjectName\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    720\u001b[0m     )\n",
      "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_ITERABLE] Column is not iterable."
     ]
    }
   ],
   "source": [
    "integrate_dataset(df_dataset, dataset, \"BlockGroup\", \"properties.NAME\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_prefix = \"BlockGroup_\"\n",
    "\n",
    "final_block_edges = {}\n",
    "final_block_nodes = {}\n",
    "\n",
    "for blocks_file_name, df_blocks in blocks_dataframes.items():\n",
    "    blocks = blocks_file_name.replace('.geojson', '')\n",
    "    print(blocks)\n",
    "    df_blocks = blocks_dataframes[blocks_file_name]\n",
    "\n",
    "    df_blocks_contain_dataset = create_relationships_point(df_blocks, df_dataset)\n",
    "    \n",
    "    df_dataset_isPartOf_block_edges = create_edge_df(df_blocks_contain_dataset, concat(lit(dataset_prefix), col(\"child_properties.NAME\")), lit(\"isPartOf\"), concat(lit(block_prefix), col(\"parent_properties.GEOID\")))\n",
    "    # df_dataset_isPartOf_block_edges.show(n=1, truncate=False)\n",
    "    final_block_edges[f'DatasetIsPartOf{blocks}Blocks'] = df_dataset_isPartOf_block_edges\n",
    "\n",
    "    df_block_contains_dataset_edges = create_edge_df(df_blocks_contain_dataset, concat(lit(block_prefix), col(\"parent_properties.GEOID\")), lit(\"Contains\"), concat(lit(dataset_prefix), col(\"child_properties.NAME\")))\n",
    "    # df_block_contains_dataset_edges.show(n=1, truncate=False)\n",
    "    final_block_edges[f'{blocks}BlockContainsDataset'] = df_block_contains_dataset_edges\n",
    "\n",
    "    df_nodes = create_node_df(df_dataset_isPartOf_block_edges, lit(dataset))\n",
    "    df_nodes = df_nodes.filter(~col(\"Node_ID\").contains(f\"{block_prefix}_\"))\n",
    "    final_block_nodes[f'{blocks}Blocks'] = df_nodes\n",
    "    # df_nodes.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_block_edges_df = union_all(final_block_edges)\n",
    "combined_block_nodes_df = union_all(final_block_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_csv(combined_block_nodes_df, base_nodes_path) # Append to Base Graph\n",
    "append_to_csv(combined_block_edges_df, base_edges_path) # Append to Base Graph\n",
    "create_csv(combined_block_edges_df, dataset_nodes_path) # Create Dataset Edges File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HydroCarbonGasLiquidPipelines (Blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'HydroCarbonGasLiquidPipelines'\n",
    "\n",
    "dataset_nodes_path = f\"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/dataset_graphs/{dataset}Nodes.csv\"\n",
    "dataset_edges_path = f\"hdfs://columbus-oh.cs.colostate.edu:30785/geospatial/dataset_graphs/{dataset}Edges.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = get_file_to_df(f'{dataset}.geojson')\n",
    "df_dataset.show(n=1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"properties\": {\n",
    "#     \"FID\": 28,\n",
    "#     \"Opername\": \"ENERGY TRANSFER\",\n",
    "#     \"Pipename\": \"West Texas Pipeline\",\n",
    "#     \"Shape_Leng\": 9.96270805248,\n",
    "#     \"Shape__Length\": 1148322.03802495\n",
    "# }\n",
    "\n",
    "dataset_prefix = lit(dataset + \"_\")\n",
    "\n",
    "# Attach all properties (Node_ID is the forein id)\n",
    "df_nodes = df_dataset.withColumn(\"Node_ID\", concat(dataset_prefix, col(\"properties.Pipename\"))) \\\n",
    "                 .withColumn(\"Type\", lit(\"HydroCarbonGasLiquidPipelines\")) \\\n",
    "                 .withColumn(\"Opername\", col(\"properties.Opername\")) \\\n",
    "                 .withColumn(\"FID\", col(\"properties.FID\")) \n",
    "\n",
    "df_nodes = df_nodes.withColumn(\"geometry\", expr(\"ST_AsGeoJSON(geometry)\"))\n",
    "\n",
    "df_nodes = df_nodes.drop(\"properties\")\n",
    "\n",
    "df_nodes.show(n=5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv(df_nodes, dataset_nodes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_prefix = \"BlockGroup_\"\n",
    "\n",
    "final_block_edges = {}\n",
    "final_block_nodes = {}\n",
    "\n",
    "for blocks_file_name, df_blocks in blocks_dataframes.items():\n",
    "    blocks = blocks_file_name.replace('.geojson', '')\n",
    "    print(blocks)\n",
    "    df_blocks_contain_dataset = create_relationships_geometry(df_blocks, df_dataset)\n",
    "    \n",
    "    df_dataset_isPartOf_block_edges = create_edge_df(df_blocks_contain_dataset, concat(lit(dataset_prefix), col(\"child_properties.Pipename\")), lit(\"isPartOf\"), concat(lit(block_prefix), col(\"parent_properties.GEOID\")))\n",
    "    # df_dataset_isPartOf_block_edges.show(n=1, truncate=False)\n",
    "    final_block_edges[f'DatasetIsPartOf{blocks}Blocks'] = df_dataset_isPartOf_block_edges\n",
    "\n",
    "    df_block_contains_dataset_edges = create_edge_df(df_blocks_contain_dataset, concat(lit(block_prefix), col(\"parent_properties.GEOID\")), lit(\"Contains\"), concat(lit(dataset_prefix), col(\"child_properties.Pipename\")))\n",
    "    # df_block_contains_dataset_edges.show(n=1, truncate=False)\n",
    "    final_block_edges[f'{blocks}BlockContainsDataset'] = df_block_contains_dataset_edges\n",
    "\n",
    "    df_nodes = create_node_df(df_block_contains_dataset_edges, lit(dataset))\n",
    "    df_nodes = df_nodes.filter(~col(\"Node_ID\").contains(f\"{dataset_prefix}_\"))\n",
    "    final_block_nodes[f'{blocks}Blocks'] = df_nodes\n",
    "    # df_nodes.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_block_edges_df = union_all(final_block_edges)\n",
    "combined_block_nodes_df = union_all(final_block_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_block_edges_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_block_nodes_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_csv(combined_block_nodes_df, base_nodes_path) # Append to Base Graph\n",
    "append_to_csv(combined_block_edges_df, base_edges_path) # Append to Base Graph\n",
    "create_csv(combined_block_edges_df, dataset_nodes_path) # Create Dataset Edges File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HydroCarbonGasLiquidPipelines (Counties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_prefix = \"County_\"\n",
    "\n",
    "final_county_edges = {}\n",
    "final_county_nodes = {}\n",
    "\n",
    "for counties_file_name, df_counties in counties_dataframes.items():\n",
    "    counties = counties_file_name.replace('.geojson', '')\n",
    "    print(counties)\n",
    "\n",
    "    df_counties_contain_dataset = create_relationships_geometry(df_counties, df_dataset)\n",
    "    \n",
    "    df_dataset_isPartOf_counties_edges = create_edge_df(df_counties_contain_dataset, concat(lit(dataset_prefix), col(\"child_properties.Pipename\")), lit(\"isPartOf\"), concat(lit(county_prefix), col(\"parent_properties.NAME\")))\n",
    "    df_dataset_isPartOf_counties_edges.show(n=1, truncate=False)\n",
    "    final_county_edges[f'DatasetIsPartOf{counties}Counties'] = df_dataset_isPartOf_counties_edges\n",
    "\n",
    "    df_county_contains_dataset_edges = create_edge_df(df_counties_contain_dataset, concat(lit(county_prefix), col(\"parent_properties.NAME\")), lit(\"Contains\"), concat(lit(dataset_prefix), col(\"child_properties.Pipename\")))\n",
    "    df_county_contains_dataset_edges.show(n=1, truncate=False)\n",
    "    final_county_edges[f'{counties}CountiesContainsDataset'] = df_county_contains_dataset_edges\n",
    "\n",
    "    df_nodes = create_node_df(df_county_contains_dataset_edges, lit(dataset))\n",
    "    df_nodes = df_nodes.filter(~col(\"Node_ID\").contains(f\"{dataset_prefix}_\"))\n",
    "    final_county_nodes[f'{blocks}Blocks'] = df_nodes\n",
    "    df_nodes.show(truncate=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_county_edges_df = union_all(final_county_edges)\n",
    "combined_county_nodes_df = union_all(final_county_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_county_edges_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_county_nodes_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_csv(combined_county_nodes_df, base_nodes_path) # Append to Base Graph\n",
    "append_to_csv(combined_county_edges_df, base_edges_path) # Append to Base Graph\n",
    "create_csv(combined_county_edges_df, dataset_nodes_path) # Create Dataset Edges File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oil Refineries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'OilRefineries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'OilRefineries'\n",
    "\n",
    "# \"properties\": {\n",
    "#     \"OBJECTID\": 18,\n",
    "#     \"REF_ID\": \"REF220020\",\n",
    "#     \"NAME\": \"LAKE CHARLES\",\n",
    "#     \"ADDRESS\": \"1601 HWY 108 E\",\n",
    "#     \"CITY\": \"SULPHUR\",\n",
    "#     \"STATE\": \"LA\",\n",
    "#     \"ZIP\": \"70665\",\n",
    "#     \"ZIP4\": \"NOT AVAILABLE\",\n",
    "#     \"TELEPHONE\": \"(337) 708-8431\",\n",
    "#     \"TYPE\": \"MODERN DEEP-CONVERSION FACILITY\",\n",
    "#     \"STATUS\": \"IN SERVICE\",\n",
    "#     \"POPULATION\": 1183,\n",
    "#     \"COUNTY\": \"CALCASIEU\",\n",
    "#     \"COUNTYFIPS\": \"22019\",\n",
    "#     \"COUNTRY\": \"USA\",\n",
    "#     \"LATITUDE\": 30.17866697000005,\n",
    "#     \"LONGITUDE\": -93.33023517799995,\n",
    "#     \"NAICS_CODE\": \"324110\",\n",
    "#     \"NAICS_DESC\": \"PETROLEUM REFINERIES\",\n",
    "#     \"SOURCE\": \"EIA-820; EPA TRI\",\n",
    "#     \"SOURCEDATE\": \"2017/01/01 00:00:00\",\n",
    "#     \"VAL_METHOD\": \"IMAGERY/OTHER\",\n",
    "#     \"VAL_DATE\": \"2018/01/31 00:00:00\",\n",
    "#     \"WEBSITE\": \"http://citgorefining.com\",\n",
    "#     \"OWNER\": \"PDV AMERICA INC\",\n",
    "#     \"OPERNAME\": \"CITGO PETROLEUM CORP\",\n",
    "#     \"RMP_ID\": \"55717\",\n",
    "#     \"EPA_ID\": \"100000140199\",\n",
    "#     \"POSREL\": \"WITHIN 166 FEET\",\n",
    "#     \"CAPACITY\": 425000,\n",
    "#     \"US_RANK\": 6,\n",
    "#     \"CRUDE\": 425000,\n",
    "#     \"VACDIST\": 230000,\n",
    "#     \"COKING\": 85410,\n",
    "#     \"THERMALOP\": 0,\n",
    "#     \"CATCRACK\": 143000,\n",
    "#     \"CATREFORM\": 103035,\n",
    "#     \"CATHYDCRCK\": 46000,\n",
    "#     \"CATHYDTRT\": 398200,\n",
    "#     \"ALKY\": 26400,\n",
    "#     \"POLDIM\": 0,\n",
    "#     \"AROMATIC\": 20900,\n",
    "#     \"ISOMER\": 28000,\n",
    "#     \"LUBES\": 0,\n",
    "#     \"OXYGENATES\": 0,\n",
    "#     \"HYDRGN\": 0,\n",
    "#     \"COKE\": 32820,\n",
    "#     \"SULFUR\": 717,\n",
    "#     \"ASPHALT\": 0\n",
    "# }\n",
    "\n",
    "\n",
    "dataset_prefix = lit(dataset + \"_\")\n",
    "\n",
    "# Attach all properties (Node_ID is the forein id)\n",
    "df_nodes = df.withColumn(\"Node_ID\", concat(dataset_prefix, col(\"properties.NAME\"))) \\\n",
    "                 .withColumn(\"Type\", lit(\"OilRefineries\")) \\\n",
    "                 .withColumn(\"CAPACITY\", col(\"properties.CAPACITY\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaturalGasStorageFacilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'NaturalGasStorageFacilities'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"properties\": {\n",
    "#     \"FID\": 12,\n",
    "#     \"STFID\": \"STF190012\",\n",
    "#     \"NAME\": \"COLUMBUS CITY\",\n",
    "#     \"ADDRESS\": \"120TH STREET/S AVE\",\n",
    "#     \"CITY\": \"COLUMBUS CITY\",\n",
    "#     \"STATE\": \"IA\",\n",
    "#     \"ZIP\": \"52738\",\n",
    "#     \"ZIP4\": \"NOT AVAILABLE\",\n",
    "#     \"TELEPHONE\": \"NOT AVAILABLE\",\n",
    "#     \"TYPE\": \"AQUIFER\",\n",
    "#     \"STATUS\": \"ACTIVE\",\n",
    "#     \"POPULATION\": -999,\n",
    "#     \"COUNTY\": \"LOUISA\",\n",
    "#     \"COUNTYFIPS\": \"19115\",\n",
    "#     \"COUNTRY\": \"USA\",\n",
    "#     \"LATITUDE\": 41.234864,\n",
    "#     \"LONGITUDE\": -91.350155,\n",
    "#     \"NAICS_CODE\": \"486210\",\n",
    "#     \"NAICS_DESC\": \"STORAGE OF NATURAL GAS\",\n",
    "#     \"SOURCE\": \"EIA, IMAGERY\",\n",
    "#     \"SOURCEDATE\": \"2018/12/01 00:00:00\",\n",
    "#     \"VAL_METHOD\": \"IMAGERY/OTHER\",\n",
    "#     \"VAL_DATE\": \"2019/04/10 00:00:00\",\n",
    "#     \"WEBSITE\": \"http://www.kindermorgan.com/\",\n",
    "#     \"EPAID\": \"155321\",\n",
    "#     \"OWNER\": \"KINDER MORGAN (NATURAL GAS PIPELINE CO OF AMERICA)\",\n",
    "#     \"OPERATOR\": \"NATURAL GAS PIPELINE CO OF AMERICA\",\n",
    "#     \"POSREL\": \"EXCEEDS 1 MILE\",\n",
    "#     \"OWNERPCT\": 100,\n",
    "#     \"MAXDEL\": 175000,\n",
    "#     \"WORKCAP\": 16685000,\n",
    "#     \"BASEGAS\": 37700000,\n",
    "#     \"TOTALCAP\": 54400193,\n",
    "#     \"REGION\": \"MIDWEST REGION\",\n",
    "#     \"PROPMAX\": -999,\n",
    "#     \"PROPWORK\": -999,\n",
    "#     \"PROPTOTAL\": -999,\n",
    "#     \"RESERVNAME\": \"GALESVILLE MT. SIMON ST. PETER\",\n",
    "#     \"SEC_NAICS\": \"NOT APPLICABLE\",\n",
    "#     \"SEC_N_DESC\": \"NOT APPLICABLE\"\n",
    "# }\n",
    "\n",
    "\n",
    "dataset_prefix = lit(dataset + \"_\")\n",
    "\n",
    "# Attach all properties (Node_ID is the forein id)\n",
    "df_nodes = df.withColumn(\"Node_ID\", concat(dataset_prefix, col(\"properties.NAME\"))) \\\n",
    "                 .withColumn(\"Type\", lit(\"NaturalGasStorageFacilities\")) \\\n",
    "                 .withColumn(\"Total Capacity\", col(\"properties.TOTALCAP\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaturalGasProcessingPlants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'NaturalGasProcessingPlants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"properties\": {\n",
    "#     \"OBJECTID\": 5,\n",
    "#     \"NGPPID\": \"NGPP010177\",\n",
    "#     \"NAME\": \"DOGWOOD OAKS PLANT\",\n",
    "#     \"ADDRESS\": \"21680 HWY 41\",\n",
    "#     \"CITY\": \"BREWTON\",\n",
    "#     \"STATE\": \"AL\",\n",
    "#     \"ZIP\": \"36426\",\n",
    "#     \"ZIP4\": \"NOT AVAILABLE\",\n",
    "#     \"TELEPHONE\": \"(251) 248-2903\",\n",
    "#     \"TYPE\": \"NATURAL GAS PROCESSING PLANT\",\n",
    "#     \"STATUS\": \"ACTIVE\",\n",
    "#     \"POPULATION\": 12,\n",
    "#     \"COUNTY\": \"ESCAMBIA\",\n",
    "#     \"COUNTYFIPS\": \"01053\",\n",
    "#     \"COUNTRY\": \"USA\",\n",
    "#     \"LATITUDE\": 31.243471,\n",
    "#     \"LONGITUDE\": -87.187836,\n",
    "#     \"NAICS_CODE\": \"211130\",\n",
    "#     \"NAICS_DESC\": \"NATURAL GAS EXTRACTION\",\n",
    "#     \"SOURCE\": \"EPA RISK MANAGEMENT PLAN (RMP) - THE RIGHT-TO-KNOW NETWORK\",\n",
    "#     \"SOURCEDATE\": \"2013/03/22 00:00:00\",\n",
    "#     \"VAL_METHOD\": \"IMAGERY/OTHER\",\n",
    "#     \"VAL_DATE\": \"2015/06/17 00:00:00\",\n",
    "#     \"WEBSITE\": \"www.plainsallamerican.com/\",\n",
    "#     \"FACID\": \"100000218356\",\n",
    "#     \"COMPNAME\": \"PLAINS GAS SOLUTIONS, LLC\",\n",
    "#     \"POSREL\": \"WITHIN 40 FEET\",\n",
    "#     \"OPERATOR\": \"CDM MAX, L.L.C. (PLAINS GAS SOLUTIONS, LLC)\",\n",
    "#     \"OPERADDR\": \"333 CLAY STREET, SUITE 1600\",\n",
    "#     \"OPERCITY\": \"HOUSTON\",\n",
    "#     \"OPERSTATE\": \"TX\",\n",
    "#     \"OPERCNTRY\": \"USA\",\n",
    "#     \"OPERZIP\": \"77002\",\n",
    "#     \"OPERPHONE\": \"(251) 248-2903\",\n",
    "#     \"OPERURL\": \"www.plainsallamerican.com/about-us/subsidiary-websites/plains-gas-solutions/facilities\",\n",
    "#     \"GASCAP\": 4,\n",
    "#     \"PROCAMTBLS\": 186840,\n",
    "#     \"BASIN\": \"GULF COAST COAL REGION\",\n",
    "#     \"PLANTFLOW\": 4,\n",
    "#     \"BTUCONTENT\": 1000,\n",
    "#     \"GASSTORCAP\": -999,\n",
    "#     \"LIQSTORCAP\": 1000,\n",
    "#     \"RMP_ID\": \"1000032802\",\n",
    "#     \"EPA_ID\": \"110055375883\"\n",
    "# }\n",
    "\n",
    "\n",
    "dataset_prefix = lit(dataset + \"_\")\n",
    "\n",
    "# Attach all properties (Node_ID is the forein id)\n",
    "df_nodes = df.withColumn(\"Node_ID\", concat(dataset_prefix, col(\"properties.NAME\"))) \\\n",
    "                 .withColumn(\"Type\", lit(\"NaturalGasProcessingPlants\")) \\\n",
    "                 .withColumn(\"Plant Flow\", col(\"properties.PLANTFLOW\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaturalGasCompressorStations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'GeographicRegions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"properties\": { \n",
    "#     \"scalerank\": 7.0, \n",
    "#     \"featurecla\": \"Island\", \n",
    "#     \"name\": \"Adak\", \n",
    "#     \"namealt\": null, \n",
    "#     \"region\": \"North America\", \n",
    "#     \"subregion\": null \n",
    "# }\n",
    "\n",
    "dataset_prefix = lit(dataset + \"_\")\n",
    "\n",
    "# Attach all properties (Node_ID is the forein id)\n",
    "df_nodes = df.withColumn(\"Node_ID\", concat(dataset_prefix, col(\"properties.name\"))) \\\n",
    "                 .withColumn(\"Type\", lit(\"GeographicRegions\")) \\\n",
    "                 .withColumn(\"Scale Rank\", col(\"properties.scalerank\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PowerPlants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'PowerPlants'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"properties\": {\n",
    "#     \"PGM_SYS_AC\": \"EIA-860\",\n",
    "#     \"PGM_SYS_ID\": \"124\",\n",
    "#     \"REGISTRY_I\": \"110002569569\",\n",
    "#     \"PRIMARY_NA\": \"TUCSON ELECTRIC POWER DEMOSS-PETRIE DSL\",\n",
    "#     \"LOCATION_A\": \"2501 NORTH FLOWING WELLS ROAD\",\n",
    "#     \"CITY_NAME\": \"TUCSON\",\n",
    "#     \"COUNTY_NAM\": \"PIMA\",\n",
    "#     \"STATE_CODE\": \"AZ\",\n",
    "#     \"POSTAL_COD\": \"85705-4015\",\n",
    "#     \"FEDERAL_FA\": \"N\",\n",
    "#     \"TRIBAL_LAN\": \"\",\n",
    "#     \"DATA_QUALI\": \"V\",\n",
    "#     \"LAST_REPOR\": \"\",\n",
    "#     \"CREATE_DAT\": \"2000-03-01\",\n",
    "#     \"UPDATE_DAT\": \"2014-04-30\",\n",
    "#     \"LATITUDE83\": 32.2523193359375,\n",
    "#     \"LONGITUDE8\": -110.99149322509766,\n",
    "#     \"REF_POINT_\": \"CENTER OF A FACILITY OR STATION\",\n",
    "#     \"DERIVED_HU\": \"15050301\",\n",
    "#     \"DERIVED_WB\": \"150503010906\",\n",
    "#     \"DERIVED_CB\": \"040190045044008\",\n",
    "#     \"DERIVED_CD\": \"02\",\n",
    "#     \"OZONE_8HR_\": \"\",\n",
    "#     \"PB_2008_AR\": \"\",\n",
    "#     \"PM25_1997_\": \"\",\n",
    "#     \"PM25_2006_\": \"\",\n",
    "#     \"OZONE_8H_1\": \"\",\n",
    "#     \"UTILITY_ID\": \"24211\",\n",
    "#     \"UTILITY_NA\": \"Tucson Electric Power Co\",\n",
    "#     \"PLANT_CODE\": \"124\",\n",
    "#     \"PLANT_NAME\": \"Demoss Petrie\",\n",
    "#     \"GENERATOR_\": \"GT2\",\n",
    "#     \"PRIME_MOVE\": \"GT\",\n",
    "#     \"STATUS\": \"OP\",\n",
    "#     \"NAMEPLATE\": 85,\n",
    "#     \"SUMMER_CAP\": 72.19999694824219,\n",
    "#     \"WINTER_CAP\": 83.30000305175781,\n",
    "#     \"UNIT_CODE\": \"\",\n",
    "#     \"OPERATING_\": \"6\",\n",
    "#     \"OPERATIN_1\": \"2001\",\n",
    "#     \"ENERGY_SOU\": \"NG\",\n",
    "#     \"ENERGY_S_1\": \"\",\n",
    "#     \"ENERGY_S_2\": \"\",\n",
    "#     \"ENERGY_S_3\": \"\",\n",
    "#     \"ENERGY_S_4\": \"\",\n",
    "#     \"ENERGY_S_5\": \"\",\n",
    "#     \"MULTIPLE_F\": \"N\",\n",
    "#     \"DELIVER_PO\": \"Y\",\n",
    "#     \"SYNCHRONIZ\": \"\",\n",
    "#     \"OWNERSHIP\": \"S\",\n",
    "#     \"TURBINES\": \".\",\n",
    "#     \"COGENERATO\": \"N\",\n",
    "#     \"SECTOR_NAM\": \"Electric Utility\",\n",
    "#     \"SECTOR\": \"1\",\n",
    "#     \"TOPPING_BO\": \"\",\n",
    "#     \"DUCT_BURNE\": \"N\",\n",
    "#     \"PLANNED_MO\": \"N\",\n",
    "#     \"PLANNED_UP\": \".\",\n",
    "#     \"PLANNED__1\": \".\",\n",
    "#     \"PLANNED__2\": \".\",\n",
    "#     \"PLANNED__3\": \".\",\n",
    "#     \"PLANNED_DE\": \".\",\n",
    "#     \"PLANNED__4\": \".\",\n",
    "#     \"PLANNED__5\": \".\",\n",
    "#     \"PLANNED__6\": \".\",\n",
    "#     \"PLANNED_NE\": \"\",\n",
    "#     \"PLANNED_EN\": \"\",\n",
    "#     \"PLANNED_RE\": \".\",\n",
    "#     \"PLANNED__7\": \".\",\n",
    "#     \"OTHER_MODS\": \"\",\n",
    "#     \"OTHER_MOD_\": \".\",\n",
    "#     \"OTHER_MO_1\": \".\",\n",
    "#     \"PLANNED__8\": \".\",\n",
    "#     \"PLANNED__9\": \".\",\n",
    "#     \"SFG_SYSTEM\": \"N\",\n",
    "#     \"PULVERIZED\": \"\",\n",
    "#     \"FLUIDIZED_\": \"\",\n",
    "#     \"SUBCRITICA\": \"\",\n",
    "#     \"SUPERCRITI\": \"\",\n",
    "#     \"ULTRASUPER\": \"\",\n",
    "#     \"CARBONCAPT\": \"\",\n",
    "#     \"STARTUP_SO\": \"\",\n",
    "#     \"STARTUP__1\": \"\",\n",
    "#     \"STARTUP__2\": \"\",\n",
    "#     \"STARTUP__3\": \"\",\n",
    "#     \"ENERGY_SRC\": \"Natural Gas\",\n",
    "#     \"ENERGY_S_6\": \"\"\n",
    "# }\n",
    "\n",
    "dataset_prefix = lit(dataset + \"_\")\n",
    "\n",
    "# Attach all properties (Node_ID is the forein id)\n",
    "df_nodes = df.withColumn(\"Node_ID\", concat(dataset_prefix, col(\"properties.PRIMARY_NA\"))) \\\n",
    "                 .withColumn(\"Type\", lit(\"PowerPlants\")) \\\n",
    "                 .withColumn(\"Summer Capacity\", col(\"properties.SUMMER_CAP\")) \\\n",
    "                .withColumn(\"Winter Capacity\", col(\"properties.WINTER_CAP\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaturalGasPipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'NaturalGasPipelines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"properties\": {\n",
    "#     \"TYPEPIPE\": \"Intrastate\",\n",
    "#     \"Operator\": \"Crosstex Texas Systems\",\n",
    "#     \"Shape_Leng\": 0.00187974387,\n",
    "#     \"Shape__Len\": 240.3441469695\n",
    "# }\n",
    "\n",
    "dataset_prefix = lit(dataset + \"_\")\n",
    "\n",
    "# Attach all properties (Node_ID is the forein id)\n",
    "df_nodes = df.withColumn(\"Node_ID\", concat(dataset_prefix, col(\"properties.Operator\"))) \\\n",
    "                 .withColumn(\"Type\", lit(\"NaturalGasPipelines\")) \\\n",
    "                 .withColumn(\"Pipe Type\", col(\"properties.TYPEPIPE\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Dams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \"properties\": {\n",
    "#     \"OBJECTID\": 9144,\n",
    "#     \"NGAID\": \"10130292\",\n",
    "#     \"METLNKID\": \"\",\n",
    "#     \"FEATTYPE\": \"POLYLINE\",\n",
    "#     \"NAME\": \"EL PASO DAM NO 10\",\n",
    "#     \"CITY\": \"EL PASO\",\n",
    "#     \"STATE\": \"TX\",\n",
    "#     \"COUNTY\": \"EL PASO\",\n",
    "#     \"FIPS\": \"48141\",\n",
    "#     \"DIRECTIONS\": \"\",\n",
    "#     \"EMERGTITLE\": \"\",\n",
    "#     \"EMERGPHONE\": \"\",\n",
    "#     \"EMERGEXT\": \"\",\n",
    "#     \"CONTDATE\": \"1899-11-30T00:00:00.000Z\",\n",
    "#     \"CONTHOW\": \"\",\n",
    "#     \"GEODATE\": \"2007-03-28T00:00:00.000Z\",\n",
    "#     \"GEOHOW\": \"MANUAL\",\n",
    "#     \"HSIPTHEMES\": \"CRITICAL INFRASTUCTURE, PDD-63; WATER SUPPLY; DAMS\",\n",
    "#     \"SOURCE\": \"USACE\",\n",
    "#     \"X\": -106.4814352,\n",
    "#     \"Y\": 31.7778363,\n",
    "#     \"QC_QA\": \"\",\n",
    "#     \"RECORDID\": \"72827\",\n",
    "#     \"OTHER_NAME\": \"\",\n",
    "#     \"FORM_NAME\": \"\",\n",
    "#     \"STATEID\": \"\",\n",
    "#     \"NIDID\": \"TX07023\",\n",
    "#     \"SECTION\": \"3106-432\",\n",
    "#     \"RIVER\": \"OFF CH-RIO GRANDE\",\n",
    "#     \"CITYAFFECT\": \"EL PASO\",\n",
    "#     \"NIDSTATE\": \"TX\",\n",
    "#     \"NIDCOUNTY\": \"EL PASO\",\n",
    "#     \"DISTANCE\": 0,\n",
    "#     \"OWN_TYPE\": \"L\",\n",
    "#     \"PRIV_DAM\": \"\",\n",
    "#     \"DAM_TYPE\": \"RE\",\n",
    "#     \"CORE\": \"XX\",\n",
    "#     \"FOUND\": \"U\",\n",
    "#     \"PURPOSES\": \"C\",\n",
    "#     \"YR_COMPL\": \"\",\n",
    "#     \"YR_MOD\": \"\",\n",
    "#     \"DAM_LENGTH\": 0,\n",
    "#     \"DAM_HEIGHT\": 30,\n",
    "#     \"STR_HEIGHT\": 0,\n",
    "#     \"HYD_HEIGHT\": 0,\n",
    "#     \"NID_HEIGHT\": 30,\n",
    "#     \"MAX_DIS\": 0,\n",
    "#     \"MAX_STOR\": 24,\n",
    "#     \"NORMAL_STO\": 0,\n",
    "#     \"NID_STOR\": 24,\n",
    "#     \"SURF_AREA\": 0,\n",
    "#     \"DRAIN_AREA\": 0,\n",
    "#     \"HAZARD\": \"H\",\n",
    "#     \"EAP\": \"N\",\n",
    "#     \"INSP_DATE\": \"1996-07-17T00:00:00.000Z\",\n",
    "#     \"INSP_FREQU\": 0,\n",
    "#     \"ST_REG_DAM\": \"Y\",\n",
    "#     \"ST_REG_AG\": \"\",\n",
    "#     \"SPILL_TYPE\": \"U\",\n",
    "#     \"SPILL_WIDT\": 12,\n",
    "#     \"OUT_GATES\": \"\",\n",
    "#     \"VOLUME\": 0,\n",
    "#     \"NO_LOCKS\": 0,\n",
    "#     \"LEN_LOCKS\": 0,\n",
    "#     \"WID_LOCKS\": 0,\n",
    "#     \"FED_FUND\": \"\",\n",
    "#     \"FED_DESIGN\": \"\",\n",
    "#     \"FED_CONSTR\": \"\",\n",
    "#     \"FED_REG\": \"\",\n",
    "#     \"FED_INSP\": \"\",\n",
    "#     \"FED_OPER\": \"\",\n",
    "#     \"FED_OWN\": \"\",\n",
    "#     \"FED_OTHER\": \"\",\n",
    "#     \"SOURCE_A\": \"TX\",\n",
    "#     \"SUB_DATE\": \"20000401\",\n",
    "#     \"URL_ADDRES\": \"HTTP://WWW.TCEQ.STATE.TX.US/\",\n",
    "#     \"CONG_DIST\": \"TX16\",\n",
    "#     \"SHAPE_Leng\": 216.77816378547902\n",
    "# }\n",
    "\n",
    "dataset_prefix = lit(dataset + \"_\")\n",
    "\n",
    "# Attach all properties (Node_ID is the forein id)\n",
    "df_nodes = df.withColumn(\"Node_ID\", concat(dataset_prefix, col(\"properties.NAME\"))) \\\n",
    "                 .withColumn(\"Type\", lit(\"Dams\")) \\\n",
    "                 .withColumn(\"River\", col(\"properties.RIVER\")) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
