{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Excavating New Datasets via GeoSpatial Insights from Datalakes**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eric Martin <br>\n",
    "Federico Larrieu <br>\n",
    "CS 555 Distributed Systems <br>\n",
    "Colorado State University <br>\n",
    "Spring 2024 <br>\n",
    "\n",
    "### Objective\n",
    "\n",
    "    • Perform analytics over a large-scale temporal network\n",
    "\n",
    "### Overview\n",
    "In this assignment, I will perform an analysis of a continuously evolving temporal network. Large-scale networks are observed in many different sociological and scientific settings such as computer networks, networks of social media, academic/technical citation networks and hyperlink networks. To understand such networks, there have been several properties of interest based primarily on two key measurements: the degrees of nodes and the shortest distances between pairs of nodes. The node-to-node distances often infer the graph’s diameter, which is the maximum shortest distance among all the connected pairs of nodes. \n",
    "\n",
    "Most of the large networks evolve over time by adding new members/items and relationships between them or removing some of them. In the traditional temporal network analysis, there are two major hypotheses. \n",
    "\n",
    "    (a) the average node degree in the network remains constant over time.\n",
    "    (Or the number of edges grows linearly in the number of nodes.). \n",
    "\n",
    "    (b) the diameter is a slowly growing function of the network size. \n",
    "\n",
    "    How are these hypothesis (a) and (b) reflected in real-world data?\n",
    "\n",
    "In this assignment, I measure fundamental network properties with a \n",
    "citation network and investigate how they evolve. I will perform the following computations using Apache Spark.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset for this assignment is the arXiv citation graph ( J. Gehrke, P. Ginsparg, and J. M. Kleinberg. Overview of the 2003 kdd cup. SIGKDD Explorations, 5(2):149–151, 2003) that covers papers published in the period from January 1993 to April 2003 (11 years). \n",
    "\n",
    "Please note that the dataset for the last year (2003) is incomplete and does not represent the entire year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Exercises on the basic Spark features\n",
    "\n",
    "In this task, I will practice with the key features of the Apache Spark.\n",
    "\n",
    "    (1) Count the number of unique published papers per year - create an output file with the number of papers published each year.\n",
    "\n",
    "    (2) Count the number of edges (citations) generated per year - create an output file with the number of citations added each year.\n",
    "\n",
    "\n",
    "First I am going to transfer my two datasets to the HDFS file system. I will use the following commands to transfer the files to the HDFS file system.\n",
    "\n",
    "1) Start HDFS on NameNode\n",
    "    ```bash\n",
    "    start-dfs.sh\n",
    "    ```\n",
    "2) Start YARN on ResourceManager\n",
    "    ```bash\n",
    "    start-yarn.sh\n",
    "    ```\n",
    "3) Start Spark on the NameNode \n",
    "    start-master.sh\n",
    "    start-workers.sh\n",
    "    ```\n",
    "4) Transfer the files to HDFS\n",
    "    ```bash\n",
    "        hadoop fs -mkdir /pa1\n",
    "        hadoop fs -mkdir /pa1/input\n",
    "        hadoop fs -put cs535/PA1/citations-redo.txt /pa1/input\n",
    "        hadoop fs -put cs535/PA1/published-dates-redo.txt /pa1/input\n",
    "    ```\n",
    "5) Verify the files are in HDFS\n",
    "    5.1) Set up SSH with tunneling\n",
    "    ```bash\n",
    "        ssh -L 8080:localhost:8080 ebmartin@hartford.cs.colostate.edu\n",
    "    ```\n",
    "    5.2) Find HDFS web address \n",
    "    ```bash\n",
    "        cd hadoopConf\n",
    "        vim hdfs-site.xml\n",
    "    ```\n",
    "    5.3) Find the following:\n",
    "    ```xml\n",
    "        <property>\n",
    "            <name>dfs.namenode.http-address</name>\n",
    "            <value>hartford.cs.colostate.edu:30182</value>\n",
    "            <description>Location of the DFS web UI</description>\n",
    "        </property>\n",
    "    ``````\n",
    "    5.4) Open local web browser and go to HDFS web address (http://<namenode>:<port>)\n",
    "    ```bash\n",
    "        http://hartford.cs.colostate.edu:30182/\n",
    "    ```\n",
    "    5.5) Verify files are in HDFS\n",
    "    ```bash\n",
    "        http://hartford.cs.colostate.edu:30182/explorer.html#/pa1/input\n",
    "    ```\n",
    "6) Check the YARN web portal to see if the Spark application is running (http://<resource_manager_host>:<port>)\n",
    "    ```bash\n",
    "        http://honolulu.cs.colostate.edu:30194/\n",
    "    ```\n",
    "7) Check the Spark web portal to see if the Spark application is running (http://<SPARK_MASTER_IP>:<SPARK_MASTER_WEBUI_PORT>)\n",
    "    ```bash\n",
    "        http://hartford.cs.colostate.edu:30197/\n",
    "    ```\n",
    "    *Note:*\n",
    "    *I wrote all this so I can reference how I did it in future assignments.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n",
      "/usr/bin/python3.9\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/usr/local/python-env/py39/lib/python3.9/site-packages\")\n",
    "\n",
    "import pyspark\n",
    "print(pyspark.__version__)\n",
    "\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialze a SparkSession\n",
    "\n",
    "Initialize a test session to ensure the SparkSession is working properly. This will connect to the resource manager node that is running the YARN cluster. If we visit the YARN web portal, we can see that the Spark application is running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring the pyspark library is being accessed from my local usr directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3.9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Sedona version: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "sedona_version = pkg_resources.get_distribution(\"apache-sedona\").version\n",
    "print(f\"Apache Sedona version: {sedona_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/latest\n",
      "/usr/bin/python3.9\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['SPARK_HOME'])\n",
    "print(os.environ['PYSPARK_PYTHON'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to make the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SedonaKepler import, verify if keplergl is installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://artifacts.unidata.ucar.edu/repository/unidata-all added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /s/chopin/l/grad/ebmartin/.ivy2/cache\n",
      "The jars for the packages stored in: /s/chopin/l/grad/ebmartin/.ivy2/jars\n",
      "org.apache.sedona#sedona-spark-3.5_2.12 added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0580c216-7ddb-43cc-b8ad-89bad055763f;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.sedona#sedona-spark-3.5_2.12;1.5.1 in central\n",
      "\tfound org.apache.sedona#sedona-common;1.5.1 in central\n",
      "\tfound org.apache.commons#commons-math3;3.6.1 in local-m2-cache\n",
      "\tfound org.locationtech.jts#jts-core;1.19.0 in central\n",
      "\tfound org.wololo#jts2geojson;0.16.1 in central\n",
      "\tfound org.locationtech.spatial4j#spatial4j;0.8 in central\n",
      "\tfound com.google.geometry#s2-geometry;2.0.0 in central\n",
      "\tfound com.google.guava#guava;25.1-jre in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in local-m2-cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark/3.5.0-with-hadoop3.3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.checkerframework#checker-qual;2.0.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.1.3 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in local-m2-cache\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.14 in central\n",
      "\tfound com.uber#h3;4.1.1 in central\n",
      "\tfound net.sf.geographiclib#GeographicLib-Java;1.52 in central\n",
      "\tfound com.github.ben-manes.caffeine#caffeine;2.9.2 in central\n",
      "\tfound org.checkerframework#checker-qual;3.10.0 in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.5.1 in central\n",
      "\tfound org.apache.sedona#sedona-spark-common-3.5_2.12;1.5.1 in central\n",
      "\tfound commons-lang#commons-lang;2.6 in local-m2-cache\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.5.0 in central\n",
      "\tfound org.beryx#awt-color-factory;1.0.0 in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.5.1-28.2 in central\n",
      ":: resolution report :: resolve 300ms :: artifacts dl 14ms\n",
      "\t:: modules in use:\n",
      "\tcom.github.ben-manes.caffeine#caffeine;2.9.2 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from local-m2-cache in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.5.1 from central in [default]\n",
      "\tcom.google.geometry#s2-geometry;2.0.0 from central in [default]\n",
      "\tcom.google.guava#guava;25.1-jre from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from local-m2-cache in [default]\n",
      "\tcom.uber#h3;4.1.1 from central in [default]\n",
      "\tcommons-lang#commons-lang;2.6 from local-m2-cache in [default]\n",
      "\tnet.sf.geographiclib#GeographicLib-Java;1.52 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.6.1 from local-m2-cache in [default]\n",
      "\torg.apache.sedona#sedona-common;1.5.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-3.5_2.12;1.5.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-common-3.5_2.12;1.5.1 from central in [default]\n",
      "\torg.beryx#awt-color-factory;1.0.0 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.10.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.14 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.5.1-28.2 from central in [default]\n",
      "\torg.locationtech.jts#jts-core;1.19.0 from central in [default]\n",
      "\torg.locationtech.spatial4j#spatial4j;0.8 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.5.0 from central in [default]\n",
      "\torg.wololo#jts2geojson;0.16.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.checkerframework#checker-qual;2.0.0 by [org.checkerframework#checker-qual;3.10.0] in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.1.3 by [com.google.errorprone#error_prone_annotations;2.5.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   23  |   0   |   0   |   2   ||   21  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0580c216-7ddb-43cc-b8ad-89bad055763f\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 21 already retrieved (0kB/6ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "/tmp/ipykernel_3639536/4208096476.py:35: DeprecationWarning: Call to deprecated function registerAll (Deprecated since 1.4.1, use SedonaContext.create() instead.).\n",
      "  SedonaRegistrator.registerAll(spark)\n",
      "/s/chopin/l/grad/ebmartin/.local/lib/python3.9/site-packages/sedona/register/geo_registrator.py:45: DeprecationWarning: Call to deprecated function register (Deprecated since 1.4.1, use SedonaContext.create() instead.).\n",
      "  cls.register(spark)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType, DateType\n",
    "from pyspark.sql.functions import year  # used to extract year from date, could do this manually as well\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import sum as pyspark_sum\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import SedonaKryoRegistrator, KryoSerializer\n",
    "from sedona.spark import *\n",
    "import geopandas as gpd\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName('GeoSpatialQueries_eric') \\\n",
    "    .master('spark://hartford:30196') \\\n",
    "    .config(\"spark.yarn.resourcemanager.address\", \"honolulu.cs.colostate.edu:30190\") \\\n",
    "    .config(\"spark.serializer\", KryoSerializer.getName) \\\n",
    "    .config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName) \\\n",
    "    .config('spark.jars.packages',\n",
    "            'org.apache.sedona:sedona-spark-3.5_2.12:1.5.1,'\n",
    "            'org.datasyslab:geotools-wrapper:1.5.1-28.2') \\\n",
    "    .config('spark.jars.repositories', 'https://artifacts.unidata.ucar.edu/repository/unidata-all') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to DEBUG\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "sedona = SedonaContext.create(spark)\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# create a logger\n",
    "logger = spark._jvm.org.apache.log4j.LogManager.getLogger(__name__)\n",
    "logger.info(\"Pyspark initialized...\")\n",
    "\n",
    "# IF YOU WANT TO RUN THE TEST, SET isTest = True\n",
    "isTest = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "\n",
    "Got the code for this from https://sedona.apache.org/1.5.1/tutorial/sql/\n",
    "\n",
    "Load GeoJSON using Spark JSON Data Source:\n",
    "\n",
    "Spark SQL's built-in JSON data source supports reading GeoJSON data. To ensure proper parsing of the geometry property, we can define a schema with the geometry property set to type 'string'. This prevents Spark from interpreting the property and allows us to use the ST_GeomFromGeoJSON function for accurate geometry parsing.\n",
    "\n",
    "```python\n",
    "schema = \"type string, crs string, totalFeatures long, features array<struct<type string, geometry string, properties map<string, string>>>\";\n",
    "(sedona.read.json(geojson_path, schema=schema)\n",
    "    .selectExpr(\"explode(features) as features\") # Explode the envelope to get one feature per row.\n",
    "    .select(\"features.*\") # Unpack the features struct.\n",
    "    .withColumn(\"geometry\", f.expr(\"ST_GeomFromGeoJSON(geometry)\")) # Convert the geometry string.\n",
    "    .printSchema())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary module from py4j to interact with JVM\n",
    "from py4j.java_gateway import java_import\n",
    "\n",
    "# Import the Path class from Hadoop. This class is used to handle file paths in Hadoop.\n",
    "java_import(spark._jvm, 'org.apache.hadoop.fs.Path')\n",
    "\n",
    "# Define a function to recursively get all .json and .geojson files in a directory and its subdirectories\n",
    "def get_files_recursive(path):\n",
    "    # Use the listStatus method of the FileSystem class to get an array of FileStatus objects\n",
    "    # Each FileStatus object represents a file or directory in the given path\n",
    "    file_status_arr = fs.listStatus(spark._jvm.Path(path))\n",
    "    \n",
    "    # Initialize an empty list to hold the file paths\n",
    "    file_paths = []\n",
    "    \n",
    "    # Loop through each FileStatus object in the array\n",
    "    for file_status in file_status_arr:\n",
    "        # If the FileStatus object represents a directory\n",
    "        if file_status.isDirectory():\n",
    "            # Call the get_files_recursive function with the directory path\n",
    "            # This is a recursive call, which means the function calls itself\n",
    "            # Add the returned file paths to the file_paths list\n",
    "            file_paths += get_files_recursive(file_status.getPath().toString())\n",
    "        # If the FileStatus object represents a file that ends with .json or .geojson\n",
    "        elif file_status.getPath().getName().endswith(('.json', '.geojson')):\n",
    "            # Add the file path to the file_paths list\n",
    "            file_paths.append(file_status.getPath().toString())\n",
    "    \n",
    "    # Return the list of file paths\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/AgriculturalArea/AgriculturalArea.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/CityBoundaries/CityBoundaries.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/CountryTerritories/CountryTerritories.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/EcoRegions/EcoRegions.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeographicRegions/GeographicRegions.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Areas_diapiric_structures.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Bathymetry.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Calderas.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Diapiric_trends.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Diapirs.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Dikes_sills.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Faults.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Gas_fluid_seep.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Gas_oil_seep.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Geologic_contacts.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Geologic_overprints.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Geologic_units.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Glaciation_extents.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Hydrothermal_vents.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Impact_structure_great_10_KM.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Impact_structure_less_10_KM.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Maganifeorus_deposits.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Phosphate_nodules_pavement.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Polymetallic_sulfide_deposits.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Rock_in_seafloor_sample.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Special_submarine_features.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/GeologicalFeatures/Volcanoes.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/WorldContinents/WorldContinents.geojson\n",
      "Processing file: hdfs://hartford.cs.colostate.edu:30181/geospatial/input/cb_2018_us_state_20m.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize a Hadoop file system \n",
    "fs = spark._jvm.org.apache.hadoop.fs.FileSystem.get(spark._jsc.hadoopConfiguration())\n",
    "\n",
    "# Directory containing the files\n",
    "json_directory = \"hdfs://hartford.cs.colostate.edu:30181/geospatial/input/\"\n",
    "\n",
    "# Define the schema for the GeoJSON data\n",
    "geojsonSchema = \"type string, crs string, totalFeatures long, features array<struct<type string, geometry string, properties map<string, string>>>\"\n",
    "\n",
    "\n",
    "if isTest:\n",
    "\n",
    "    # Path to the GeoJSON file\n",
    "    geojson_path = \"hdfs://hartford.cs.colostate.edu:30181/geospatial/input/cb_2018_us_state_20m.json\"\n",
    "\n",
    "    # Read the GeoJSON file using the defined schema using sedona into a spark dataframe\n",
    "    state_boundaries_sedona = spark.read.schema(geojsonSchema).json(geojson_path, multiLine=True)\n",
    "    \n",
    "    # Explode the features array to create a row for each feature and select the columns\n",
    "    state_boundaries_sedona = (state_boundaries_sedona\n",
    "                               .select(F.explode(\"features\").alias(\"features\"))\n",
    "                               .select(\"features.*\")\n",
    "                               # Use Sedona's ST_GeomFromGeoJSON function to convert the geometry string to a geometry object\n",
    "                               .withColumn(\"geometry\", F.expr(\"ST_GeomFromGeoJSON(geometry)\"))\n",
    "                              )\n",
    "\n",
    "else:\n",
    "    # Get a list of the JSON and GeoJSON files in the directory and its subdirectories\n",
    "    json_files = get_files_recursive(json_directory)\n",
    "\n",
    "    # Create a dictionary to hold the DataFrames\n",
    "    json_dataset_dataframes = {}\n",
    "\n",
    "    # Define the current and desired EPSG codes\n",
    "    current_epsg = \"EPSG:3857\"  # Web Mercator\n",
    "    desired_epsg = \"EPSG:4326\"  # WGS84\n",
    "\n",
    "    # Load each JSON file into a DataFrame and store it in the dictionary\n",
    "    for file_path in json_files:\n",
    "        file_name = file_path.split('/')[-1]\n",
    "        \n",
    "        # Print the file path\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Read the GeoJSON file using the defined schema using sedona into a spark dataframe\n",
    "        df = spark.read.schema(geojsonSchema).json(file_path, multiLine=True)\n",
    "        \n",
    "        # Explode the features array to create a row for each feature and select the columns\n",
    "        df = (df\n",
    "            .select(F.explode(\"features\").alias(\"features\"))\n",
    "            .select(\"features.*\")\n",
    "            # Use Sedona's ST_GeomFromGeoJSON function to convert the geometry string to a geometry object\n",
    "            .withColumn(\"geometry\", F.expr(\"ST_GeomFromGeoJSON(geometry)\"))\n",
    "            # Transform the 'geometry' column from the current EPSG code to the desired EPSG code\n",
    "            .withColumn(\"geometry\", F.expr(f\"ST_Transform(geometry, '{current_epsg}', '{desired_epsg}')\"))\n",
    "            )\n",
    "        \n",
    "        json_dataset_dataframes[file_name] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see that the datasets are not in a workable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgriculturalArea.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "CityBoundaries.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "CountryTerritories.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "EcoRegions.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "GeographicRegions.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Areas_diapiric_structures.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Bathymetry.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Calderas.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Diapiric_trends.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Diapirs.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Dikes_sills.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Faults.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Gas_fluid_seep.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Gas_oil_seep.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Geologic_contacts.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Geologic_overprints.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Geologic_units.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Glaciation_extents.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Hydrothermal_vents.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Impact_structure_great_10_KM.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Impact_structure_less_10_KM.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Maganifeorus_deposits.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Phosphate_nodules_pavement.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Polymetallic_sulfide_deposits.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Rock_in_seafloor_sample.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Special_submarine_features.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "Volcanoes.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "WorldContinents.geojson Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "cb_2018_us_state_20m.json Schema:\n",
      "root\n",
      " |-- type: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the schemas\n",
    "\n",
    "if (isTest):\n",
    "    print(\"State Boundaries Sedona Schema:\")\n",
    "    state_boundaries_sedona.printSchema()\n",
    "else:\n",
    "    for key, value in json_dataset_dataframes.items():\n",
    "        print(f\"{key} Schema:\")\n",
    "        value.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first 5 rows of the state_boundaries_sedona DataFrame\n",
    "\n",
    "if (isTest):\n",
    "    state_boundaries_sedona.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Spatial Queries\n",
    "\n",
    "https://sedona.apache.org/1.5.1/api/sql/Function/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Range Query\n",
    "\n",
    "This example demonstrates how to perform a range query using ST_Contains to find geometries within a specified polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_boundaries_sedona' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m bbox_polygon \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST_PolygonFromEnvelope(-79.5, 37.9, -75.6, 39.8)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Perform the range query to find features within the bounding box\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m contained_features \u001b[38;5;241m=\u001b[39m \u001b[43mstate_boundaries_sedona\u001b[49m\u001b[38;5;241m.\u001b[39mfilter(\n\u001b[1;32m      7\u001b[0m     F\u001b[38;5;241m.\u001b[39mexpr(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST_Contains(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbbox_polygon\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, geometry)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Show results\u001b[39;00m\n\u001b[1;32m     11\u001b[0m contained_features\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'state_boundaries_sedona' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a polygon using ST_PolygonFromEnvelope and perform a range query\n",
    "\n",
    "bbox_polygon = \"ST_PolygonFromEnvelope(-79.5, 37.9, -75.6, 39.8)\"\n",
    "\n",
    "# Perform the range query to find features within the bounding box\n",
    "contained_features = state_boundaries_sedona.filter(\n",
    "    F.expr(f\"ST_Contains({bbox_polygon}, geometry)\")\n",
    ")\n",
    "\n",
    "# Show results\n",
    "contained_features.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Query\n",
    "\n",
    "This example demonstrates how to perform a k-nearest neighbors (KNN) query using ST_Distance to find the k nearest geometries to a specified point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                NAME|           distance|\n",
      "+--------------------+-------------------+\n",
      "|            Virginia|                0.0|\n",
      "|            Maryland| 0.2425364842513449|\n",
      "|       West Virginia|0.39633443061384227|\n",
      "|District of Columbia|0.43843022219048333|\n",
      "|        Pennsylvania| 0.8705736535332227|\n",
      "+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Calculate the center of the bounding box and create a WKT representation of the point\n",
    "center_longitude = (-79.5 + -75.6) / 2\n",
    "center_latitude = (37.9 + 39.8) / 2\n",
    "center_point_wkt = f\"POINT({center_longitude} {center_latitude})\"\n",
    "\n",
    "# Perform the KNN query using ST_Distance to calculate the distance to the center point\n",
    "knnQueryResult = state_boundaries_sedona.select(\n",
    "    # Access the 'NAME' from the 'properties' map\n",
    "    F.col(\"properties\").getItem(\"NAME\").alias(\"NAME\"),\n",
    "    F.expr(f\"ST_Distance(ST_GeomFromWKT('{center_point_wkt}'), geometry)\").alias(\"distance\")\n",
    ").orderBy(\"distance\").limit(5)\n",
    "\n",
    "knnQueryResult.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|   type|            geometry|          properties|\n",
      "+-------+--------------------+--------------------+\n",
      "|Feature|MULTIPOLYGON (((-...|{STATEFP -> 24, S...|\n",
      "|Feature|POLYGON ((-96.621...|{STATEFP -> 19, S...|\n",
      "|Feature|POLYGON ((-75.773...|{STATEFP -> 10, S...|\n",
      "|Feature|MULTIPOLYGON (((-...|{STATEFP -> 39, S...|\n",
      "|Feature|POLYGON ((-80.519...|{STATEFP -> 42, S...|\n",
      "|Feature|POLYGON ((-104.05...|{STATEFP -> 31, S...|\n",
      "|Feature|MULTIPOLYGON (((-...|{STATEFP -> 53, S...|\n",
      "|Feature|MULTIPOLYGON (((-...|{STATEFP -> 72, S...|\n",
      "|Feature|POLYGON ((-88.468...|{STATEFP -> 01, S...|\n",
      "|Feature|POLYGON ((-94.617...|{STATEFP -> 05, S...|\n",
      "|Feature|POLYGON ((-109.04...|{STATEFP -> 35, S...|\n",
      "|Feature|POLYGON ((-106.62...|{STATEFP -> 48, S...|\n",
      "|Feature|MULTIPOLYGON (((-...|{STATEFP -> 06, S...|\n",
      "|Feature|POLYGON ((-89.544...|{STATEFP -> 21, S...|\n",
      "|Feature|POLYGON ((-85.605...|{STATEFP -> 13, S...|\n",
      "|Feature|MULTIPOLYGON (((-...|{STATEFP -> 55, S...|\n",
      "|Feature|POLYGON ((-124.55...|{STATEFP -> 41, S...|\n",
      "|Feature|POLYGON ((-95.765...|{STATEFP -> 29, S...|\n",
      "|Feature|MULTIPOLYGON (((-...|{STATEFP -> 51, S...|\n",
      "|Feature|POLYGON ((-90.300...|{STATEFP -> 47, S...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "state_boundaries_sedona.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the precision for the GeoHash\n",
    "precision = 17\n",
    "\n",
    "# Apply the ST_GeoHash function to each DataFrame in the dictionary\n",
    "for file_name, df in json_dataset_dataframes.items():\n",
    "    # Add a new column 'geohash' to the DataFrame\n",
    "    # The new column is the GeoHash of the 'geometry' column with the given precision\n",
    "    df = df.withColumn('geohash', F.expr(f\"ST_GeoHash(geometry, {precision})\"))\n",
    "    \n",
    "    # Update the DataFrame in the dictionary\n",
    "    json_dataset_dataframes[file_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: AgriculturalArea.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|POLYGON ((-86.411...|{atlas_stco -> 01...|djf2gyhbv2zcvfuq5|\n",
      "|Feature|POLYGON ((-87.765...|{atlas_stco -> 01...|dj3xh3s29uwyntq0h|\n",
      "|Feature|POLYGON ((-85.051...|{atlas_stco -> 01...|djem2sjezsn8d3f48|\n",
      "|Feature|POLYGON ((-86.881...|{atlas_stco -> 01...|djf5bys527zx3dc1w|\n",
      "|Feature|POLYGON ((-86.303...|{atlas_stco -> 01...|dn43kxg2ne76f5uqj|\n",
      "|Feature|POLYGON ((-85.433...|{atlas_stco -> 01...|djen9drdpb0td407b|\n",
      "|Feature|POLYGON ((-86.499...|{atlas_stco -> 01...|djdkedfefunffsg28|\n",
      "|Feature|POLYGON ((-85.530...|{atlas_stco -> 01...|dn4bndnzcsk6uqfwr|\n",
      "|Feature|POLYGON ((-85.186...|{atlas_stco -> 01...|djg738ee4883qth40|\n",
      "|Feature|POLYGON ((-85.463...|{atlas_stco -> 01...|dn54exu7y6bqterch|\n",
      "|Feature|POLYGON ((-86.517...|{atlas_stco -> 01...|djf6gpjngyymyuzwy|\n",
      "|Feature|POLYGON ((-88.073...|{atlas_stco -> 01...|dj9q0fnyqf5h6q5zk|\n",
      "|Feature|POLYGON ((-87.500...|{atlas_stco -> 01...|dj9e9nsmk6dvdbtkp|\n",
      "|Feature|POLYGON ((-85.653...|{atlas_stco -> 01...|djfvmj5fs2g4sk56r|\n",
      "|Feature|POLYGON ((-85.386...|{atlas_stco -> 01...|djgpu1ywhptz38ksr|\n",
      "|Feature|POLYGON ((-85.791...|{atlas_stco -> 01...|djdfehnn260qw50tu|\n",
      "|Feature|POLYGON ((-87.426...|{atlas_stco -> 01...|dn1td6q6g43jhjd0b|\n",
      "|Feature|POLYGON ((-86.701...|{atlas_stco -> 01...|djd551rvmfsqfjxzv|\n",
      "|Feature|POLYGON ((-86.009...|{atlas_stco -> 01...|djfem499zw8u7p7k9|\n",
      "|Feature|POLYGON ((-86.193...|{atlas_stco -> 01...|djd9bfuy1nd0y1zrp|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: CityBoundaries.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|POLYGON ((-98.181...|{NAME -> Pharr, C...|9udhv9gc9gecvqr6b|\n",
      "|Feature|POLYGON ((-98.226...|{NAME -> McAllen,...|9udjhn79s44yyf1ck|\n",
      "|Feature|POLYGON ((-98.138...|{NAME -> Edinburg...|9udjyhewy9e3jpdst|\n",
      "|Feature|POLYGON ((-99.627...|{NAME -> Laredo, ...|9uchybk9yh4ghr3qh|\n",
      "|Feature|POLYGON ((-98.335...|{NAME -> Mission,...|9udj43639h5p1xxn3|\n",
      "|Feature|MULTIPOLYGON (((-...|{NAME -> San Anto...|9v1zwnv74ny5kz9dp|\n",
      "|Feature|POLYGON ((-97.615...|{NAME -> Round Ro...|9v6t9mjhcjk8p3pnp|\n",
      "|Feature|MULTIPOLYGON (((-...|{NAME -> Austin, ...|9v6krtket1p5txews|\n",
      "|Feature|MULTIPOLYGON (((-...|{NAME -> Killeen,...|9vd88s51j8bfr5cc5|\n",
      "|Feature|POLYGON ((-97.437...|{NAME -> Brownsvi...|9udsn62mw79ru7q95|\n",
      "|Feature|POLYGON ((-100.45...|{NAME -> San Ange...|9v8df609xcq644ts7|\n",
      "|Feature|POLYGON ((-96.274...|{NAME -> College ...|9v7w0bf1pfb51ye06|\n",
      "|Feature|POLYGON ((-96.274...|{NAME -> Bryan, C...|9v7qrmwhrj9yk6me0|\n",
      "|Feature|MULTIPOLYGON (((-...|{NAME -> Houston,...|9vk1esn9b6jn382rp|\n",
      "|Feature|MULTIPOLYGON (((-...|{NAME -> Sugar La...|9v7brdjdm3cdk2h8n|\n",
      "|Feature|MULTIPOLYGON (((-...|{NAME -> Pearland...|9vk0ne580e7r77hwu|\n",
      "|Feature|POLYGON ((-95.518...|{NAME -> Missouri...|9vk0450mgq9ckvq6u|\n",
      "|Feature|POLYGON ((-95.049...|{NAME -> League C...|9vhrg9jgsj1qvr1xq|\n",
      "|Feature|MULTIPOLYGON (((-...|{NAME -> Pasadena...|9vk2etrvr1nf0h9zy|\n",
      "|Feature|MULTIPOLYGON (((-...|{NAME -> Baytown,...|9vk3pr12y4k2nbgx1|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: CountryTerritories.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|POLYGON ((0.00029...|{geo_point_2d -> ...|s0000001ph9sp9kfk|\n",
      "|Feature|POLYGON ((0.00008...|{geo_point_2d -> ...|s00000043wrhgd1ze|\n",
      "|Feature|POLYGON ((-0.0000...|{geo_point_2d -> ...|ebpbpbpfxd3tppqpc|\n",
      "|Feature|POLYGON ((0.00015...|{geo_point_2d -> ...|s00000046zckv90ds|\n",
      "|Feature|POLYGON ((-0.0000...|{geo_point_2d -> ...|ebpbpbpfn672zmu2u|\n",
      "|Feature|POLYGON ((0.00005...|{geo_point_2d -> ...|s0000004973j3v8cw|\n",
      "|Feature|POLYGON ((0.00078...|{geo_point_2d -> ...|s0000006w02m0ug1k|\n",
      "|Feature|POLYGON ((-0.0006...|{geo_point_2d -> ...|ebpbpbp89kgqfgbxm|\n",
      "|Feature|POLYGON ((0.00011...|{geo_point_2d -> ...|s00000044w5mkyz6h|\n",
      "|Feature|MULTIPOLYGON (((0...|{geo_point_2d -> ...|s000000045fjz8jsn|\n",
      "|Feature|POLYGON ((-0.0006...|{geo_point_2d -> ...|ebpbpbp2zy64rw3bk|\n",
      "|Feature|MULTIPOLYGON (((0...|{geo_point_2d -> ...|s0000005j4pef48zw|\n",
      "|Feature|POLYGON ((0.00013...|{geo_point_2d -> ...|s0000000ctqps32f5|\n",
      "|Feature|MULTIPOLYGON (((-...|{geo_point_2d -> ...|ebpbpbp2vkz1nu8y3|\n",
      "|Feature|POLYGON ((-0.0000...|{geo_point_2d -> ...|ebpbpbpcwt0rxe3zu|\n",
      "|Feature|MULTIPOLYGON (((0...|{geo_point_2d -> ...|s000000by3rbt28vs|\n",
      "|Feature|MULTIPOLYGON (((0...|{geo_point_2d -> ...|s000000fqf9t0z69y|\n",
      "|Feature|MULTIPOLYGON (((0...|{geo_point_2d -> ...|s00000042mrvpqmwd|\n",
      "|Feature|POLYGON ((0.00018...|{geo_point_2d -> ...|s0000004k3snf4n67|\n",
      "|Feature|POLYGON ((-0.0004...|{geo_point_2d -> ...|7zzzzzzwk3d3q5prr|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: EcoRegions.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|POLYGON ((-20.518...|{US_L3CODE -> 1, ...|edcx39wzyh0rw2wv3|\n",
      "|Feature|POLYGON ((-20.902...|{US_L3CODE -> 1, ...|ee14sq49zdwvdswf5|\n",
      "|Feature|POLYGON ((-20.901...|{US_L3CODE -> 1, ...|ee14sr41kemvhhyee|\n",
      "|Feature|POLYGON ((-20.915...|{US_L3CODE -> 1, ...|ee14uhcuq9q0t79me|\n",
      "|Feature|POLYGON ((-20.954...|{US_L3CODE -> 1, ...|ee155jt16k77cycup|\n",
      "|Feature|POLYGON ((-20.955...|{US_L3CODE -> 1, ...|ee155nhdytpfp852m|\n",
      "|Feature|POLYGON ((-20.954...|{US_L3CODE -> 1, ...|ee155nj7xwwknfgyw|\n",
      "|Feature|POLYGON ((-20.959...|{US_L3CODE -> 1, ...|ee155p1em6ys2gsvk|\n",
      "|Feature|POLYGON ((-20.741...|{US_L3CODE -> 1, ...|ee1k3sn8m8ejswy4p|\n",
      "|Feature|POLYGON ((-20.759...|{US_L3CODE -> 1, ...|ee1jzx3bej7k47d2n|\n",
      "|Feature|POLYGON ((-20.758...|{US_L3CODE -> 1, ...|ee1npe5gm5er8qt2p|\n",
      "|Feature|POLYGON ((-20.759...|{US_L3CODE -> 1, ...|ee1np65s6g8jktnj7|\n",
      "|Feature|POLYGON ((-20.854...|{US_L3CODE -> 1, ...|ee9hjrkpb68w18pwj|\n",
      "|Feature|POLYGON ((-20.857...|{US_L3CODE -> 1, ...|ee9hm291jg8hm9n6z|\n",
      "|Feature|POLYGON ((-18.954...|{US_L3CODE -> 1, ...|es6w8ves79jq5npjn|\n",
      "|Feature|POLYGON ((-19.164...|{US_L3CODE -> 1, ...|es6rebt05cnsj0n0g|\n",
      "|Feature|POLYGON ((-19.075...|{US_L3CODE -> 1, ...|esd2mgdb5ep5q8jrk|\n",
      "|Feature|POLYGON ((-18.223...|{US_L3CODE -> 1, ...|esep8cr0cdp38y6vn|\n",
      "|Feature|POLYGON ((-19.001...|{US_L3CODE -> 1, ...|es406dj9q4v7z9puk|\n",
      "|Feature|POLYGON ((-13.734...|{US_L3CODE -> 10,...|esnpnuv6g50mbpr81|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: GeographicRegions.geojson\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|POLYGON ((0.00151...|{scalerank -> 7.0...|kpbpbpcp5jwt7cwgm|\n",
      "|Feature|POLYGON ((0.00152...|{scalerank -> 7.0...|kpbpbpcngw1mzvb5w|\n",
      "|Feature|POLYGON ((0.00150...|{scalerank -> 7.0...|kpbpbpcp701vwbw8c|\n",
      "|Feature|POLYGON ((0.00149...|{scalerank -> 7.0...|kpbpbpcp6v53xzsdk|\n",
      "|Feature|POLYGON ((0.00149...|{scalerank -> 7.0...|kpbpbpcp6ut88wwe5|\n",
      "|Feature|POLYGON ((-0.0015...|{scalerank -> 7.0...|ebpbpbnfen8rjejnm|\n",
      "|Feature|POLYGON ((-0.0014...|{scalerank -> 7.0...|ebpbpbnfvetkyuru1|\n",
      "|Feature|POLYGON ((-0.0001...|{scalerank -> 7.0...|ebpbpbpct0ss6c2zh|\n",
      "|Feature|POLYGON ((0.00035...|{scalerank -> 7.0...|kpbpbpbr8r6667kmr|\n",
      "|Feature|POLYGON ((0.00049...|{scalerank -> 7.0...|kpbpbpbrg85tbnj2g|\n",
      "|Feature|POLYGON ((0.00039...|{scalerank -> 7.0...|kpbpbpbr35mh8tqfg|\n",
      "|Feature|POLYGON ((0.00040...|{scalerank -> 7.0...|kpbpbpbr36w34jwv5|\n",
      "|Feature|POLYGON ((0.00039...|{scalerank -> 7.0...|kpbpbpbr3791n5c2b|\n",
      "|Feature|POLYGON ((0.00035...|{scalerank -> 7.0...|kpbpbpbr86fkbnycx|\n",
      "|Feature|POLYGON ((-0.0002...|{scalerank -> 7.0...|ebpbpbpf16ncqwg50|\n",
      "|Feature|POLYGON ((-0.0002...|{scalerank -> 7.0...|ebpbpbpf406mrj741|\n",
      "|Feature|POLYGON ((-0.0002...|{scalerank -> 7.0...|ebpbpbpf42cfb3prn|\n",
      "|Feature|POLYGON ((-0.0002...|{scalerank -> 7.0...|ebpbpbpcftzvdmhqw|\n",
      "|Feature|POLYGON ((-0.0002...|{scalerank -> 7.0...|ebpbpbpbfch2pugfk|\n",
      "|Feature|POLYGON ((-0.0002...|{scalerank -> 7.0...|ebpbpbpbfgv8tux7j|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: Areas_diapiric_structures.geojson\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|POLYGON ((30.1676...|{Shape_Area -> 5....|u8jr5bkdxf4zcyxy1|\n",
      "|Feature|POLYGON ((32.1729...|{Shape_Area -> 4....|u8qujjgcrthmsn74w|\n",
      "|Feature|POLYGON ((31.3514...|{Shape_Area -> 1....|u8wk9pdkdjvxmbhhv|\n",
      "|Feature|POLYGON ((31.6987...|{Shape_Area -> 1....|u8w8dfvrxf3upqcfh|\n",
      "|Feature|POLYGON ((32.6848...|{Shape_Area -> 1....|u8rr35ez21pq7ds4w|\n",
      "|Feature|POLYGON ((31.8276...|{Shape_Area -> 3....|u8wtkzy150h5hfunq|\n",
      "|Feature|POLYGON ((31.7660...|{Shape_Area -> 1....|u8y8gsug5628khp6w|\n",
      "|Feature|POLYGON ((32.0500...|{Shape_Area -> 7....|u8qg3gmfqsyhu4eru|\n",
      "|Feature|POLYGON ((31.3515...|{Shape_Area -> 4....|u8q3fp4qb9d5wrxnr|\n",
      "|Feature|POLYGON ((33.0437...|{Shape_Area -> 5....|u8xkwze3v3cvz6nnf|\n",
      "|Feature|POLYGON ((32.7521...|{Shape_Area -> 1....|u8xm3vm1unxqeqbzz|\n",
      "|Feature|POLYGON ((32.0876...|{Shape_Area -> 1....|u8qszctwpzrb3292m|\n",
      "|Feature|POLYGON ((9.30234...|{Shape_Area -> 5....|u5q951r3rhsvr81tr|\n",
      "|Feature|POLYGON ((31.7363...|{Shape_Area -> 8....|u8wsmhwj19wp7t0w9|\n",
      "|Feature|POLYGON ((30.8316...|{Shape_Area -> 9....|u8tyjgjvh64kd86cv|\n",
      "|Feature|POLYGON ((32.2640...|{Shape_Area -> 3....|u8xj8w5n4r1d3b7dd|\n",
      "|Feature|POLYGON ((32.6471...|{Shape_Area -> 1....|u8rhp3x2gpc825kp1|\n",
      "|Feature|POLYGON ((31.9922...|{Shape_Area -> 4....|u8wybhy95b86fgvqm|\n",
      "|Feature|POLYGON ((31.0855...|{Shape_Area -> 1....|u8wntgjbmvshb69hg|\n",
      "|Feature|POLYGON ((31.3891...|{Shape_Area -> 1....|u8wqh43verjbw56vm|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: Bathymetry.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|LINESTRING (-21.6...|{Shape_Leng -> 2....|eqvmurp1s9wk843kk|\n",
      "|Feature|LINESTRING (12.94...|{Shape_Leng -> 2....|ewr2mz5h211j65se7|\n",
      "|Feature|LINESTRING (13.91...|{Shape_Leng -> 1....|ewr8kx0hr35vk5e7q|\n",
      "|Feature|LINESTRING (16.96...|{Shape_Leng -> 2....|ey22rx4s7c5mr5e7k|\n",
      "|Feature|LINESTRING (39.94...|{Shape_Leng -> 3....|sqqyp8hk3sgcw9dg3|\n",
      "|Feature|LINESTRING (39.94...|{Shape_Leng -> 3....|sqrn2g7854y781wyw|\n",
      "|Feature|LINESTRING (39.94...|{Shape_Leng -> 2....|sxh5kqjxrfn1qc23v|\n",
      "|Feature|LINESTRING (39.94...|{Shape_Leng -> 2....|sxh8renumeznh52fn|\n",
      "|Feature|LINESTRING (39.94...|{Shape_Leng -> 1....|swkzyyu9dcdb8upd4|\n",
      "|Feature|LINESTRING (-17.2...|{Shape_Leng -> 30...|exkrqpwcxy7xpmk84|\n",
      "|Feature|LINESTRING (-38.6...|{Shape_Leng -> 1....|ercgtxukcrck7e31k|\n",
      "|Feature|LINESTRING (-10.7...|{Shape_Leng -> 64...|gftvdckc5h660vd7g|\n",
      "|Feature|LINESTRING (-10.6...|{Shape_Leng -> 1....|gftyexm8808mwkemx|\n",
      "|Feature|LINESTRING (7.622...|{Shape_Leng -> 57...|gftv389m3egge2yjb|\n",
      "|Feature|LINESTRING (-11.3...|{Shape_Leng -> 15...|eu4hqzh222x9nn12h|\n",
      "|Feature|LINESTRING (-21.6...|{Shape_Leng -> 17...|es0tk4z4z0rv2ve51|\n",
      "|Feature|LINESTRING (-21.6...|{Shape_Leng -> 98...|es09gyfg0knwfv1up|\n",
      "|Feature|LINESTRING (-21.6...|{Shape_Leng -> 29...|es09uwfv7uxrse5y2|\n",
      "|Feature|LINESTRING (-21.6...|{Shape_Leng -> 69...|eebwe9mk4qcd7t24q|\n",
      "|Feature|LINESTRING (-21.6...|{Shape_Leng -> 25...|eebvfxw8f1zdsbc63|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: Calderas.geojson\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|LINESTRING (24.93...|{Shape_Leng -> 38...|udcxqq29xver79fpg|\n",
      "|Feature|LINESTRING (24.62...|{Shape_Leng -> 47...|udcrx5cbpwgnk7gue|\n",
      "|Feature|LINESTRING (24.33...|{Shape_Leng -> 34...|ue1k1fzugn8wtswgb|\n",
      "|Feature|LINESTRING (23.67...|{Shape_Leng -> 42...|ue0fc3hfvhr4pyxcw|\n",
      "|Feature|LINESTRING (23.74...|{Shape_Leng -> 37...|ue0b72d516ztm5rnz|\n",
      "|Feature|LINESTRING (22.36...|{Shape_Leng -> 14...|u6zgs6cuhj2kz42ew|\n",
      "|Feature|LINESTRING (23.35...|{Shape_Leng -> 25...|udbt596cx5u1sy8hk|\n",
      "|Feature|LINESTRING (23.35...|{Shape_Leng -> 34...|udbte25w1swm8pkbt|\n",
      "|Feature|LINESTRING (-20.3...|{Shape_Leng -> 50...|ge1td13r2w8zdj2rt|\n",
      "|Feature|LINESTRING (-21.2...|{Shape_Leng -> 50...|ge0ys5ff8th5ec5jb|\n",
      "|Feature|LINESTRING (-21.8...|{Shape_Leng -> 27...|ge0rr1nxngdtbv9ut|\n",
      "|Feature|LINESTRING (-21.5...|{Shape_Leng -> 25...|ge0x7p6fb5ctp7m8x|\n",
      "|Feature|LINESTRING (-20.1...|{Shape_Leng -> 89...|ge1tp81q23m7yuwk2|\n",
      "|Feature|LINESTRING (-21.1...|{Shape_Leng -> 63...|ge0zhv6x34zvj3sn7|\n",
      "|Feature|LINESTRING (-20.3...|{Shape_Leng -> 74...|ge1rr35166b9gh95b|\n",
      "|Feature|LINESTRING (-21.1...|{Shape_Leng -> 48...|ge31104ps7t739s42|\n",
      "|Feature|LINESTRING (-21.1...|{Shape_Leng -> 47...|ge2cxwd9pz0udpkv9|\n",
      "|Feature|LINESTRING (-22.6...|{Shape_Leng -> 48...|g7rcww5mr0y8tucuc|\n",
      "|Feature|LINESTRING (-21.8...|{Shape_Leng -> 15...|gdbm43vtyhsppk8qs|\n",
      "|Feature|LINESTRING (-21.2...|{Shape_Leng -> 25...|g9bbuftqtd26fk66n|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: Diapiric_trends.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|LINESTRING (-1.98...|{Shape_Leng -> 33...|gfq9t4e745358cx17|\n",
      "|Feature|LINESTRING (5.664...|{Shape_Leng -> 78...|sh7vxdkx5n77knhpc|\n",
      "|Feature|LINESTRING (5.807...|{Shape_Leng -> 14...|shknkrm318gxpk9uq|\n",
      "|Feature|LINESTRING (5.916...|{Shape_Leng -> 30...|shknrcn8f538fq3ed|\n",
      "|Feature|LINESTRING (6.181...|{Shape_Leng -> 78...|shkmvry8hd3y5zzfp|\n",
      "|Feature|LINESTRING (6.155...|{Shape_Leng -> 57...|shkqkdjrh28pmj556|\n",
      "|Feature|LINESTRING (6.070...|{Shape_Leng -> 11...|shkqdupq089hhh22u|\n",
      "|Feature|LINESTRING (6.070...|{Shape_Leng -> 17...|shkr7f9prfj20qm4b|\n",
      "|Feature|LINESTRING (9.316...|{Shape_Leng -> 27...|shwdkznww32qqszkx|\n",
      "|Feature|LINESTRING (9.104...|{Shape_Leng -> 10...|shw8vtwynxxvuctzx|\n",
      "|Feature|LINESTRING (9.372...|{Shape_Leng -> 66...|shwdpqrub8rmm27kk|\n",
      "|Feature|LINESTRING (9.634...|{Shape_Leng -> 44...|shwctsm5y95s29x1n|\n",
      "|Feature|LINESTRING (9.437...|{Shape_Leng -> 48...|shqz4r71k84tc4jrh|\n",
      "|Feature|LINESTRING (9.128...|{Shape_Leng -> 58...|shqweze74xyz85475|\n",
      "|Feature|LINESTRING (8.746...|{Shape_Leng -> 57...|shqqdqgwd0kud7p8t|\n",
      "|Feature|LINESTRING (9.031...|{Shape_Leng -> 38...|shw2zd7dmtpwhf32h|\n",
      "|Feature|LINESTRING (8.912...|{Shape_Leng -> 72...|shw2pyv01gv1m39yr|\n",
      "|Feature|LINESTRING (8.886...|{Shape_Leng -> 46...|shw2g8wy59srcds15|\n",
      "|Feature|LINESTRING (8.813...|{Shape_Leng -> 22...|shw23tbns85u9regb|\n",
      "|Feature|LINESTRING (8.381...|{Shape_Leng -> 86...|shqpg8mk0rj62wg4u|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: Diapirs.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|POINT (30.4060414...|{SHAPE_TYPE -> Do...|u8m85cj5bjgc88ujs|\n",
      "|Feature|POINT (30.9265697...|{SHAPE_TYPE -> Do...|u8mbzz0p1kcf3r3mk|\n",
      "|Feature|POINT (30.6843429...|{SHAPE_TYPE -> Do...|u8mb65retn8kvd9b4|\n",
      "|Feature|POINT (30.2791350...|{SHAPE_TYPE -> Do...|u8jxch2x6crt91nkz|\n",
      "|Feature|POINT (30.5065310...|{SHAPE_TYPE -> Do...|u8jsy1y1tswmbxgt1|\n",
      "|Feature|POINT (30.5065634...|{SHAPE_TYPE -> Do...|u8jewnnpq2wmsfemw|\n",
      "|Feature|POINT (32.0420266...|{SHAPE_TYPE -> Do...|u8wz94sk96dwzextx|\n",
      "|Feature|POINT (32.1134005...|{SHAPE_TYPE -> Do...|u8wydb0k2mz528xvg|\n",
      "|Feature|POINT (32.4900208...|{SHAPE_TYPE -> Do...|u8xng24w03g7m7huu|\n",
      "|Feature|POINT (31.5584119...|{SHAPE_TYPE -> Do...|u8w7w5k4h73sc4rsr|\n",
      "|Feature|POINT (32.2512126...|{SHAPE_TYPE -> Do...|u8qgvgsx5srhs3yhz|\n",
      "|Feature|POINT (31.8599316...|{SHAPE_TYPE -> Do...|u8qescpxqpyuk1bfv|\n",
      "|Feature|POINT (33.9272793...|{SHAPE_TYPE -> Do...|ub2hu515fvj09qc86|\n",
      "|Feature|POINT (33.7211309...|{SHAPE_TYPE -> Do...|u8rfpm4zp71whb3qh|\n",
      "|Feature|POINT (32.0292154...|{SHAPE_TYPE -> Do...|u8qb8gdynbd40kvd8|\n",
      "|Feature|POINT (31.5851431...|{SHAPE_TYPE -> Do...|u8nmwtzt5nmb8tby8|\n",
      "|Feature|POINT (31.3948159...|{SHAPE_TYPE -> Do...|u8n7dkvh2ppd8tffq|\n",
      "|Feature|POINT (-0.8244919...|{SHAPE_TYPE -> Do...|gfr7mnzw5fnk2ftk9|\n",
      "|Feature|POINT (-0.5035075...|{SHAPE_TYPE -> Do...|gfrtu832grj8cd3yh|\n",
      "|Feature|POINT (-0.2620758...|{SHAPE_TYPE -> Do...|gfrv651ht0n0g0gqe|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: Dikes_sills.geojson\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|LINESTRING (24.99...|{DIKE_ABBRE -> Zm...|u83u0cj41kbecjxp6|\n",
      "|Feature|LINESTRING (24.94...|{DIKE_ABBRE -> Zm...|u83speypuwd8pqfw4|\n",
      "|Feature|LINESTRING (24.91...|{DIKE_ABBRE -> Zm...|u83sny5c85kkcszhs|\n",
      "|Feature|LINESTRING (24.86...|{DIKE_ABBRE -> Zm...|u83wtwquv5dqy0ngh|\n",
      "|Feature|LINESTRING (24.83...|{DIKE_ABBRE -> Zm...|u83xm5kfj1pznuuvn|\n",
      "|Feature|LINESTRING (24.84...|{DIKE_ABBRE -> Zm...|u83xv5rttfn2gmrpm|\n",
      "|Feature|LINESTRING (24.87...|{DIKE_ABBRE -> Zm...|u83xy4cnq2ntf7u8p|\n",
      "|Feature|LINESTRING (24.76...|{DIKE_ABBRE -> Zm...|u83xgq63ewz844deh|\n",
      "|Feature|LINESTRING (24.70...|{DIKE_ABBRE -> Zm...|u8984nt8sq9jfccd0|\n",
      "|Feature|LINESTRING (24.67...|{DIKE_ABBRE -> Zm...|u8981x8zqsuw0wvx7|\n",
      "|Feature|LINESTRING (24.92...|{DIKE_ABBRE -> Zm...|u898xqgytqgy43zb0|\n",
      "|Feature|LINESTRING (24.79...|{DIKE_ABBRE -> Zm...|u898umbkc7suxr5y1|\n",
      "|Feature|LINESTRING (24.75...|{DIKE_ABBRE -> Zm...|u898grc89gbyf5g9q|\n",
      "|Feature|LINESTRING (24.76...|{DIKE_ABBRE -> Zm...|u899793epecs3hm8n|\n",
      "|Feature|LINESTRING (24.85...|{DIKE_ABBRE -> Zm...|u899t83nysh0gyyff|\n",
      "|Feature|LINESTRING (24.80...|{DIKE_ABBRE -> Zm...|u899s7qb9qyw23u26|\n",
      "|Feature|LINESTRING (24.76...|{DIKE_ABBRE -> Zm...|u899ethmxfh7u81ph|\n",
      "|Feature|LINESTRING (21.60...|{DIKE_ABBRE -> Y²...|u2xm5qwqfq8tm21v4|\n",
      "|Feature|LINESTRING (21.62...|{DIKE_ABBRE -> Y²...|u2xm7y69k4y4s0w9c|\n",
      "|Feature|LINESTRING (21.59...|{DIKE_ABBRE -> Y²...|u2xme62mbwhtvptpv|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: Faults.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+-----------------+\n",
      "|   type|            geometry|          properties|          geohash|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "|Feature|LINESTRING (4.577...|{SLIP_DIR -> NULL...|shd9ex78fc8t5wtw9|\n",
      "|Feature|LINESTRING (4.058...|{SLIP_DIR -> NULL...|shd393k5ppb03whbz|\n",
      "|Feature|LINESTRING (-19.0...|{SLIP_DIR -> NULL...|ewf6jr182qmnjbnde|\n",
      "|Feature|LINESTRING (-19.3...|{SLIP_DIR -> NULL...|ewf4qx8334qkc990r|\n",
      "|Feature|LINESTRING (-19.6...|{SLIP_DIR -> NULL...|ewf4bsqkqbxjvfwnm|\n",
      "|Feature|LINESTRING (-19.0...|{SLIP_DIR -> NULL...|ewf7meqcu1u674z6v|\n",
      "|Feature|LINESTRING (-19.3...|{SLIP_DIR -> NULL...|ewdnyxnrcthgd7fd9|\n",
      "|Feature|LINESTRING (-19.2...|{SLIP_DIR -> NULL...|ewdr67mkbv9s61nqm|\n",
      "|Feature|LINESTRING (-19.3...|{SLIP_DIR -> NULL...|ewdpr7u8wjjfv3eg7|\n",
      "|Feature|LINESTRING (-19.2...|{SLIP_DIR -> NULL...|ewdqgkzr5zupje05g|\n",
      "|Feature|LINESTRING (-19.2...|{SLIP_DIR -> NULL...|ewdrg11248g89jbfn|\n",
      "|Feature|LINESTRING (-19.3...|{SLIP_DIR -> NULL...|ewdrb4w6tzfnkmp3x|\n",
      "|Feature|LINESTRING (-19.3...|{SLIP_DIR -> NULL...|ewdpuszqp1wb30ef6|\n",
      "|Feature|LINESTRING (-19.5...|{SLIP_DIR -> NULL...|ewf01szzsdbrmsd52|\n",
      "|Feature|LINESTRING (-19.1...|{SLIP_DIR -> NULL...|ewf2t92hqju3j08p1|\n",
      "|Feature|LINESTRING (-19.5...|{SLIP_DIR -> NULL...|ewf08utc6m69r88hr|\n",
      "|Feature|LINESTRING (-19.0...|{SLIP_DIR -> NULL...|ewf2uqzqq4r89ejpf|\n",
      "|Feature|LINESTRING (-19.1...|{SLIP_DIR -> NULL...|ewf2ghm3fusntxb8u|\n",
      "|Feature|LINESTRING (-19.2...|{SLIP_DIR -> NULL...|ewf30f35s2geczcd3|\n",
      "|Feature|LINESTRING (-19.2...|{SLIP_DIR -> NULL...|ewf2mz49ewzh1fz3b|\n",
      "+-------+--------------------+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: Gas_fluid_seep.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+-----------------+\n",
      "|   type|            geometry|      properties|          geohash|\n",
      "+-------+--------------------+----------------+-----------------+\n",
      "|Feature|POINT (-22.241921...| {OBJECTID -> 0}|gd2jmf5fjsv6ecn7g|\n",
      "|Feature|POINT (-16.611828...| {OBJECTID -> 1}|exhhtyrtsqgh573gt|\n",
      "|Feature|POINT (-16.493114...| {OBJECTID -> 2}|exhk8dq4d8dsgpyyg|\n",
      "|Feature|POINT (18.8519986...| {OBJECTID -> 3}|smmqkzp853tpbrzc9|\n",
      "|Feature|POINT (7.76133436...| {OBJECTID -> 4}|shmxbsedu4nqge4rd|\n",
      "|Feature|POINT (4.52164832...| {OBJECTID -> 5}|sh5pqbuxdn3r5mq6t|\n",
      "|Feature|POINT (4.47757233...| {OBJECTID -> 6}|sh7hjvhqwyrfvmmkq|\n",
      "|Feature|POINT (4.28080609...| {OBJECTID -> 7}|sh7j17vnwhb2u5y0v|\n",
      "|Feature|POINT (4.41620004...| {OBJECTID -> 8}|sh7jhqzf2ymmt9vyk|\n",
      "|Feature|POINT (4.55000298...| {OBJECTID -> 9}|sh7jrd3pncb4uj7pf|\n",
      "|Feature|POINT (5.65508131...|{OBJECTID -> 10}|shkhbttysvqr0nq7p|\n",
      "|Feature|POINT (5.74795570...|{OBJECTID -> 11}|shkj4gcw9hf2veb2f|\n",
      "|Feature|POINT (5.82508434...|{OBJECTID -> 12}|shkjks18y73xnrrhm|\n",
      "|Feature|POINT (6.11946225...|{OBJECTID -> 13}|shkme7b49y9y0gydg|\n",
      "|Feature|POINT (6.16039065...|{OBJECTID -> 14}|shkqh1mggd81w896p|\n",
      "|Feature|POINT (6.32567420...|{OBJECTID -> 15}|shkqpby5ngh89g926|\n",
      "|Feature|POINT (6.31150916...|{OBJECTID -> 16}|shkqrw7guc6rd8yfk|\n",
      "|Feature|POINT (6.41855492...|{OBJECTID -> 17}|shkt6p3v5pjqq57q7|\n",
      "|Feature|POINT (6.40596161...|{OBJECTID -> 18}|shkw1g2wm9rhqpde9|\n",
      "|Feature|POINT (6.40753997...|{OBJECTID -> 19}|shkw3zcvdd8154vq4|\n",
      "+-------+--------------------+----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "File: Gas_oil_seep.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "# Loop through each DataFrame in the dictionary\n",
    "for file_name, df in json_dataset_dataframes.items():\n",
    "    # Print the file name\n",
    "    print(f\"File: {file_name}\")\n",
    "    \n",
    "    # Show the first few rows of the DataFrame\n",
    "    df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
